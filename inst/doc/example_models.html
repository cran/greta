<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">



<title>Example models</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */


</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Example models</h1>



<div id="common-models" class="section level2">
<h2>Common models</h2>
<p>Below are a few examples of common statistical models implemented in greta.</p>
<hr>
<div id="linear-regression" class="section level3">
<h3>Linear regression</h3>
<p>A simple, one-variable Bayesian linear regression model using the attitude data</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># variables &amp; priors</span>
int &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
sd &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))

<span class="co"># linear predictor</span>
mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>attitude<span class="op">$</span>complaints

<span class="co"># observation model</span>
<span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</code></pre></div>
<hr>
</div>
<div id="multiple-linear-regression" class="section level3">
<h3>Multiple linear regression</h3>
<p>A multi-variable Bayesian linear regression model using the attitude data</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(attitude)
design &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(attitude[, <span class="dv">2</span><span class="op">:</span><span class="dv">7</span>])</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">int &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
coefs &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> <span class="kw">ncol</span>(design))
sd &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))

<span class="co"># matrix multiplication is more efficient than multiplying the coefficients</span>
<span class="co"># separately</span>
mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>design <span class="op">%*%</span><span class="st"> </span>coefs

<span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</code></pre></div>
<hr>
</div>
<div id="multiple-poisson-regression" class="section level3">
<h3>Multiple Poisson regression</h3>
<p>A multiple Bayesian linear regression model using the <code>warpbreaks</code> data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;warpbreaks&quot;</span>)
X &lt;-<span class="st"> </span><span class="kw">as_data</span>(<span class="kw">model.matrix</span>(breaks <span class="op">~</span><span class="st"> </span>wool <span class="op">+</span><span class="st"> </span>tension, warpbreaks))
y &lt;-<span class="st"> </span><span class="kw">as_data</span>(warpbreaks<span class="op">$</span>breaks)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">int &lt;-<span class="st"> </span><span class="kw">variable</span>()
coefs &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dt">dim =</span> <span class="kw">ncol</span>(X) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)
beta &lt;-<span class="st"> </span><span class="kw">c</span>(int, coefs)

eta &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>beta

<span class="kw">distribution</span>(y) &lt;-<span class="st"> </span><span class="kw">poisson</span>(<span class="kw">exp</span>(eta))</code></pre></div>
<hr>
</div>
<div id="multiple-categorical-regression" class="section level3">
<h3>Multiple categorical regression</h3>
<p>A multi-variable Bayesian categorical regression model using the iris data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(iris)
X &lt;-<span class="st"> </span><span class="kw">as_data</span>(<span class="kw">cbind</span>(<span class="dv">1</span>, iris[, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>]))
y &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="st"> </span>Species <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, iris)
P &lt;-<span class="st"> </span><span class="kw">ncol</span>(X)
K &lt;-<span class="st"> </span><span class="kw">ncol</span>(y)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dt">dim =</span> <span class="kw">c</span>(P, K <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))
eta &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>beta
prob &lt;-<span class="st"> </span><span class="kw">imultilogit</span>(eta)
<span class="kw">distribution</span>(y) &lt;-<span class="st"> </span><span class="kw">categorical</span>(prob)</code></pre></div>
<hr>
</div>
<div id="multiple-linear-regression-with-lasso-prior" class="section level3">
<h3>Multiple linear regression with LASSO prior</h3>
<p>A multi-variable Bayesian linear regression model using an exponential-normal prior for the coefficients.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(attitude)
design &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(attitude[, <span class="dv">2</span><span class="op">:</span><span class="dv">7</span>])</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">int &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
sd &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))

tau &lt;-<span class="st"> </span><span class="kw">exponential</span>(<span class="fl">0.5</span>, <span class="dt">dim =</span> <span class="kw">ncol</span>(design)) 
coefs &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, tau)
mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>design <span class="op">%*%</span><span class="st"> </span>coefs

<span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</code></pre></div>
<hr>
</div>
<div id="hierarchical-linear-regression" class="section level3">
<h3>Hierarchical linear regression</h3>
<p>A hierarchical, Bayesian linear regression model using the iris data, with random intercepts for each of the three species.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># linear model parameters</span>
int &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
sd &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))

<span class="co"># hierarchical model for species effect; use the first species as the baseline</span>
<span class="co"># like in lm()</span>
species_sd &lt;-<span class="st"> </span><span class="kw">lognormal</span>(<span class="dv">0</span>, <span class="dv">1</span>)
species_offset &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, species_sd, <span class="dt">dim =</span> <span class="dv">2</span>)
species_effect &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="dv">0</span>, species_offset)
species_id &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(iris<span class="op">$</span>Species)

<span class="co"># model</span>
mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>iris<span class="op">$</span>Sepal.Width <span class="op">+</span><span class="st"> </span>species_effect[species_id]
<span class="kw">distribution</span>(iris<span class="op">$</span>Sepal.Length) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</code></pre></div>
<hr>
</div>
<div id="random-intercept-slope-model" class="section level3">
<h3>Random intercept-slope model</h3>
<p>A hierarchical, Bayesian linear regression model using the iris data, with random intercepts and slopes for each of the three species. The slopes and intercepts for each species are <em>uncorrelated</em> in this example.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># linear model parameters</span>
int &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
sd &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))

species_id &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(iris<span class="op">$</span>Species)

<span class="co"># random intercepts</span>
species_int_sd &lt;-<span class="st"> </span><span class="kw">lognormal</span>(<span class="dv">0</span>, <span class="dv">1</span>)
species_int &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, species_int_sd, <span class="dt">dim =</span> <span class="dv">2</span>)
species_int_eff &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="dv">0</span>, species_int)

<span class="co"># random slopes</span>
species_slope_sd &lt;-<span class="st"> </span><span class="kw">lognormal</span>(<span class="dv">0</span>, <span class="dv">1</span>)
species_slope &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, species_slope_sd, <span class="dt">dim =</span> <span class="dv">2</span>)
species_slope_eff &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="dv">0</span>, species_slope)

<span class="co"># model</span>
mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>iris<span class="op">$</span>Sepal.Width <span class="op">+</span><span class="st"> </span>species_int_eff[species_id] <span class="op">+</span><span class="st"> </span>iris<span class="op">$</span>Sepal.Width <span class="op">*</span><span class="st"> </span>species_slope_eff[species_id]
<span class="kw">distribution</span>(iris<span class="op">$</span>Sepal.Length) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</code></pre></div>
</div>
</div>
<div id="common-bayesian-priors" class="section level2">
<h2>Common Bayesian priors</h2>
<p>The following examples show some common Bayesian priors of which some induce sparsity.</p>
<hr>
<div id="improper-flat-prior" class="section level3">
<h3>Improper flat prior</h3>
<p>A simple, one-variable Bayesian linear regression model that uses flat priors for the coefficients. A flat prior using <code>variable</code> puts an unbounded uniform distribution on the parameter. With unconstrained flat priors, the posterior will be proportional to the likelihood and the MAP will correspond to the MLE. Flat priors are usually chosen when there is little knowledge about the parameters available.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># variables &amp; priors</span>
int  &lt;-<span class="st"> </span><span class="kw">variable</span>()
coef &lt;-<span class="st"> </span><span class="kw">variable</span>()
sd   &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))

<span class="co"># linear predictor</span>
mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>attitude<span class="op">$</span>complaints

<span class="co"># observation model</span>
<span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</code></pre></div>
<hr>
</div>
<div id="ridge-prior" class="section level3">
<h3>Ridge prior</h3>
<p>Here we estimate a simple, one-variable Bayesian linear regression model that uses a <em>ridge</em> prior. The ridge prior has a frequentist interpretation where it is used as a penalty for regression coefficients. Among other effects, the penalty shrinks the coefficients towards zero to reduce variance without setting them to zero. The Bayesian version uses a normal distribution for the slopes and a inverse gamma prior for the strength of the penalty. Note that since the prior in our intercept is still improper, the joint prior is also improper.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># variables &amp; priors</span>
int &lt;-<span class="st"> </span><span class="kw">variable</span>()
sd &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))

tau &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)
coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, tau)

<span class="co"># linear predictor</span>
mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>attitude<span class="op">$</span>complaints

<span class="co"># observation model</span>
<span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</code></pre></div>
<hr>
</div>
<div id="exponential-normal-prior" class="section level3">
<h3>Exponential-normal prior</h3>
<p>In this example we infer the parameters of one-variable Bayesian linear regression model using an exponential-normal prior. A compound exponential-normal prior can be interpreted like an equivalent to the frequentist LASSO. The exponential-normal prior yields a posterior that is pooled towards zero. An exponential-normal prior, or equivalently a Laplace prior, is consequently often chosen when a sparse solution is assumed, which, for instance, is a natural scenario in many biological settings.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># variables &amp; priors</span>
int &lt;-<span class="st"> </span><span class="kw">variable</span>()
sd &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)

lambda &lt;-<span class="st"> </span><span class="kw">gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)
tau &lt;-<span class="st"> </span><span class="kw">exponential</span>(<span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>lambda<span class="op">**</span><span class="dv">2</span>)
coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, tau)

<span class="co"># linear predictor</span>
mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>attitude<span class="op">$</span>complaints

<span class="co"># observation model</span>
<span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</code></pre></div>
<hr>
</div>
<div id="horseshoe-prior" class="section level3">
<h3>Horseshoe prior</h3>
<p>A simple, one-variable Bayesian linear regression model using a horseshoe prior. The horseshoe, just as the LASSO, can be used when the slopes are assumed to be sparse. According to the original <a href="http://proceedings.mlr.press/v5/carvalho09a/carvalho09a.pdf">publication</a>: &gt; its flat, Cauchy-like tails allow strong signals to remain large […] &gt; a posteriori. Yet its infinitely tall spike at the origin provides &gt; severe shrinkage for the zero elements</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">horseshoe &lt;-<span class="st"> </span><span class="cf">function</span> (<span class="dt">tau =</span> <span class="dv">1</span>, <span class="dt">dim =</span> <span class="ot">NULL</span>) {
  lambda &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>), <span class="dt">dim =</span> dim)
  sd &lt;-<span class="st"> </span>tau <span class="op">^</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>lambda <span class="op">^</span><span class="st"> </span><span class="dv">2</span>
  <span class="kw">normal</span>(<span class="dv">0</span>, sd, <span class="dt">dim =</span> dim)
}

<span class="co"># variables &amp; priors</span>
int &lt;-<span class="st"> </span><span class="kw">variable</span>()
sd &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)
coef &lt;-<span class="st"> </span><span class="kw">horseshoe</span>()

<span class="co"># linear predictor</span>
mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>attitude<span class="op">$</span>complaints

<span class="co"># observation model</span>
<span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</code></pre></div>
<hr>
</div>
<div id="regularized-horseshoe-prior" class="section level3">
<h3>Regularized horseshoe prior</h3>
<p>The <a href="https://projecteuclid.org/euclid.ejs/1513306866">regularized (‘Finnish’) horseshoe</a> remedies a problem of the original horseshoe: large, unregularized values for the coefficients. This is especially problematic in scenarios where the parameters are only weakly identified by the data, as in logistic regression with perfectly seperable data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regularized_horseshoe &lt;-<span class="st"> </span><span class="cf">function</span> (<span class="dt">tau =</span> <span class="dv">1</span>,  <span class="dt">c =</span> <span class="dv">1</span>, <span class="dt">dim =</span> <span class="ot">NULL</span>) {
  <span class="kw">stopifnot</span>(c <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)
  lambda &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>), <span class="dt">dim =</span> dim)
  lambda_tilde &lt;-<span class="st"> </span>(c<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>lambda<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>(c<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>lambda<span class="op">^</span><span class="dv">2</span>)
  sd &lt;-<span class="st"> </span>tau <span class="op">^</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>lambda_tilde <span class="op">^</span><span class="st"> </span><span class="dv">2</span>
  <span class="kw">normal</span>(<span class="dv">0</span>, sd, <span class="dt">dim =</span> dim)
}

<span class="co"># variables &amp; priors</span>
int &lt;-<span class="st"> </span><span class="kw">variable</span>()
sd &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)
coef &lt;-<span class="st"> </span><span class="kw">regularized_horseshoe</span>()

<span class="co"># linear predictor</span>
mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>attitude<span class="op">$</span>complaints

<span class="co"># observation model</span>
<span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</code></pre></div>
</div>
</div>
<div id="advanced-bayesian-models" class="section level2">
<h2>Advanced Bayesian models</h2>
<p>Below are some more advanced examples implemented in greta.</p>
<hr>
<div id="hierarchical-linear-regression-in-general-conditional-formulation" class="section level3">
<h3>Hierarchical linear regression in general conditional formulation</h3>
<p>A hierarchical, Bayesian linear regression model using the iris data, with random intercepts and slopes for each of the three species. The slopes and intercepts for each species are <em>correlated</em> in this example. We allow every species to have a species specific slope for <code>Sepal.Length</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">int  &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
sd   &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))

n_species  &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(iris<span class="op">$</span>Species))
species_id &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(iris<span class="op">$</span>Species)

Z &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="st"> </span>Species <span class="op">+</span><span class="st"> </span>Sepal.Length <span class="op">*</span><span class="st"> </span>Species <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> iris)

gamma_matrix &lt;-<span class="st"> </span><span class="kw">multivariate_normal</span>(<span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>),
                                    <span class="kw">diag</span>(<span class="dv">2</span>),
                                    <span class="dt">n_realisations =</span> <span class="dv">3</span>) 
gamma &lt;-<span class="st"> </span><span class="kw">c</span>(gamma_matrix)

wi &lt;-<span class="st"> </span><span class="kw">as_data</span>(iris<span class="op">$</span>Sepal.Width)
Z  &lt;-<span class="st"> </span><span class="kw">as_data</span>(Z)
mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>wi <span class="op">+</span><span class="st"> </span>Z <span class="op">%*%</span><span class="st"> </span>gamma

<span class="kw">distribution</span>(iris<span class="op">$</span>Sepal.Length) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</code></pre></div>
<hr>
</div>
<div id="hierarchical-linear-regression-in-general-marginal-formulation" class="section level3">
<h3>Hierarchical linear regression in general marginal formulation</h3>
<p>A hierarchical, Bayesian linear regression model using the iris data, with random intercepts and slopes for each of the three species. This time we try to set up the <em>marginal</em> model, i.e. when we integrate the conditional density.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">int  &lt;-<span class="st"> </span><span class="kw">variable</span>()
coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>)
sd   &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))

n_species  &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(iris<span class="op">$</span>Species))
species_id &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(iris<span class="op">$</span>Species)

Z &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="st"> </span>Species <span class="op">+</span><span class="st"> </span>Sepal.Length <span class="op">*</span><span class="st"> </span>Species <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> iris)
G  &lt;-<span class="st"> </span><span class="kw">zeros</span>(n_species <span class="op">*</span><span class="st"> </span><span class="dv">2</span>, n_species <span class="op">*</span><span class="st"> </span><span class="dv">2</span>)

<span class="cf">for</span> (s <span class="cf">in</span> <span class="kw">unique</span>(species_id)) {
  G[<span class="kw">c</span>(s, s <span class="op">+</span><span class="st"> </span>n_species), <span class="kw">c</span>(s, s <span class="op">+</span><span class="st"> </span>n_species)] &lt;-<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>)
}

mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>iris<span class="op">$</span>Sepal.Width
V &lt;-<span class="st"> </span><span class="kw">zeros</span>(<span class="kw">nrow</span>(iris), <span class="kw">nrow</span>(iris))
<span class="kw">diag</span>(V) &lt;-<span class="st"> </span>sd

Z &lt;-<span class="st"> </span><span class="kw">as_data</span>(Z)
V &lt;-<span class="st"> </span>V <span class="op">+</span><span class="st"> </span>Z <span class="op">%*%</span><span class="st"> </span>G <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(Z)

sep &lt;-<span class="st"> </span><span class="kw">t</span>(iris<span class="op">$</span>Sepal.Width)
<span class="kw">distribution</span>(sep) &lt;-<span class="st"> </span><span class="kw">multivariate_normal</span>(<span class="kw">t</span>(mu), V)</code></pre></div>
<hr>
</div>
<div id="bayesian-neural-network" class="section level3">
<h3>Bayesian neural network</h3>
<p><em>Bayesian neural network</em> estimates an easy neural network with a normal prior on the edge weights. For clarity we use an architecture without a hidden layer, such that the weights actually correspond to coefficients in a linear regression model.</p>
<pre class="text"><code>N &lt;- 100
p &lt;- 10

set.seed(23)  
X &lt;- matrix(rnorm(N * p), N)
beta &lt;- rnorm(10)
y &lt;- X %*% beta + rnorm(N, sd = 0.1)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">neural_network &lt;-<span class="st"> </span><span class="cf">function</span>(x)
{
  <span class="co"># this can be arbitrarily complex, e.g. multiple hidden layers</span>
  x <span class="op">%*%</span><span class="st"> </span>weights
}
  
weights &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">dim =</span> <span class="kw">c</span>(p, <span class="dv">1</span>))
sd &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)

<span class="kw">distribution</span>(y) &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="kw">neural_network</span>(X), sd)</code></pre></div>
<hr>
</div>
<div id="factor-analysis" class="section level3">
<h3>Factor analysis</h3>
<p>Factor analysis is a linear latent model used for finding a lower-dimensional probabilistic description of a data set with observations <span class="math inline">\(\mathbf{x}_i \in \mathbb{R}^p\)</span>. We assume the data are generated according to <span class="math display">\[
\mathbf{x}_i = \mathbf{W} \mathbf{z}_i + \boldsymbol \mu + \epsilon_i
\]</span> where the noise <span class="math inline">\(\epsilon\)</span> is normally distributed with zero mean and diagonal covariance matrix <span class="math inline">\(\Psi = \mathrm{diag}(\psi_1, \dots, \psi_p)\)</span>. The goal of factor analysis is to estimate the latent variables <span class="math inline">\(\mathbf{z}_i \mathbb{R}^q\)</span>.</p>
<p>In this example we take the mean vector <span class="math inline">\(\boldsymbol \mu\)</span> to be zero.</p>
<div class="data">
<pre class="text"><code>generate.data &lt;- function(n = 100, p = 5, q = 2, psi = diag(rgamma(p, 1, 1)))
{
  W  &lt;- matrix(rnorm(p * q, 1), p, q)
  Z  &lt;- matrix(rnorm(q * n, 2), q, n)
  WZ &lt;- W %*% Z
  
  X  &lt;- matrix(0, n, p)
  for (i in seq_len(n)) {
    X[i, ] &lt;- MASS::mvrnorm(1, WZ[, i], psi)
  }
  
  list(X = X, W = W, Z = Z, psi = psi)
}

n &lt;- 100
p &lt;- 5
q &lt;- 2
data &lt;- generate.data(n = n, p = p, q = q)
X &lt;- data$X</code></pre>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">W &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">dim =</span> <span class="kw">c</span>(p, q))
Z &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">dim =</span> <span class="kw">c</span>(q, n))
psi &lt;-<span class="st"> </span><span class="kw">zeros</span>(p, p)
<span class="kw">diag</span>(psi) &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dt">dim =</span> p)

<span class="kw">distribution</span>(X) &lt;-<span class="st"> </span><span class="kw">multivariate_normal</span>(<span class="kw">t</span>(W <span class="op">%*%</span><span class="st"> </span>Z), psi)</code></pre></div>
</div>
</div>
<div id="bugs-models" class="section level2">
<h2>BUGS models</h2>
<p>The BUGS project provide a number of example models written in the BUGS modelling language. These models will run in WinBUGS and OpenBUGS, and likely also in JAGS. The <a href="https://github.com/stan-dev/example-models/wiki/BUGS-Examples-Sorted-Alphabetically">Stan wiki</a> provides Stan implementations of these models.</p>
<p>The following sections provide greta implementations of some of these example models, alongside the BUGS code from <a href="https://www.mrc-bsu.cam.ac.uk/wp-content/uploads/WinBUGS_Vol2.pdf">WinBUGS examples volume 2</a> (pdf) and Stan code and an R version of the data from the <a href="https://github.com/stan-dev/example-models/wiki">Stan example models wiki</a>.</p>
<hr>
<div id="air" class="section level3">
<h3>Air</h3>
<p><em>Air</em> analyses reported respiratory illness versus exposure to nitrogen dioxide in 103 children. The parameters <code>alpha</code>, <code>beta</code> and <code>sigma2</code> are known in advance, and the data are grouped into three categories.</p>
<p>See <a href="https://www.mrc-bsu.cam.ac.uk/wp-content/uploads/WinBUGS_Vol2.pdf">WinBUGS examples volume 2</a> (pdf) for details.</p>
<div id="data" class="section level4">
<h4>data</h4>
<pre class="text"><code>y &lt;- c(21, 20, 15)
n &lt;- c(48, 34, 21)
Z &lt;- c(10, 30, 50)
alpha &lt;- 4.48
beta &lt;- 0.76
sigma2 &lt;- 81.14
sigma &lt;- sqrt(sigma2)
tau &lt;- 1 / sigma2
J &lt;- 3</code></pre>
</div>
<div id="greta-code" class="section level4">
<h4>greta code</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">theta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">32</span>, <span class="dt">dim =</span> <span class="dv">2</span>)
mu &lt;-<span class="st"> </span>alpha <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>Z
X &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sigma)
p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(theta[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>theta[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>X)
<span class="kw">distribution</span>(y) &lt;-<span class="st"> </span><span class="kw">binomial</span>(n, p)</code></pre></div>
</div>
<div id="bugsjags-code" class="section level4">
<h4>BUGS/JAGS code</h4>
<div class="bugs">
<pre><code>for(j in 1 : J) {
   y[j] ~ dbin(p[j], n[j])
   logit(p[j]) &lt;- theta[1] + theta[2] * X[j]
   X[j] ~ dnorm(mu[j], tau)
   mu[j] &lt;- alpha + beta * Z[j]
}
theta[1] ~ dnorm(0.0, 0.001)
theta[2] ~ dnorm(0.0, 0.001)</code></pre>
</div>
</div>
<div id="stan-code" class="section level4">
<h4>Stan code</h4>
<div class="stan">
<pre><code>data {
  real alpha; 
  real beta; 
  real&lt;lower=0&gt; sigma2; 
  int&lt;lower=0&gt; J; 
  int y[J]; 
  vector[J] Z;
  int n[J]; 
} 

transformed data {
  real&lt;lower=0&gt; sigma; 
  sigma &lt;- sqrt(sigma2); 
} 

parameters {
   real theta1; 
   real theta2; 
   vector[J] X; 
} 

model {
  real p[J];
  theta1 ~ normal(0, 32);   // 32^2 = 1024 
  theta2 ~ normal(0, 32); 
  X ~ normal(alpha + beta * Z, sigma);
  y ~ binomial_logit(n, theta1 + theta2 * X);
}</code></pre>
</div>
<hr>
</div>
</div>
<div id="beetles" class="section level3">
<h3>Beetles</h3>
<p><em>Beetles</em> considers dose-response data from an experiment applying carbon disulphide to 8 beetles. The original example compares three different link functions; the logit, probit and complementary log-log. Here, only the code for the logit link is shown. You can implement the other two link functions in greta by changing <code>ilogit</code> to <code>iprobit</code> or <code>icloglog</code>.</p>
<p>See <a href="https://www.mrc-bsu.cam.ac.uk/wp-content/uploads/WinBUGS_Vol2.pdf">WinBUGS examples volume 2</a> (pdf) for details.</p>
<div id="data-1" class="section level4">
<h4>data</h4>
<pre class="text"><code>x &lt;- c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839)
n &lt;- c(59, 60, 62, 56, 63, 59, 62, 60)
r &lt;- c(6, 13, 18, 28, 52, 53, 61, 60)
N &lt;- 8</code></pre>
</div>
<div id="greta-code-1" class="section level4">
<h4>greta code</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alpha_star &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">32</span>)
beta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">32</span>)
p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(alpha_star <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>(x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x)))
<span class="kw">distribution</span>(r) &lt;-<span class="st"> </span><span class="kw">binomial</span>(n, p)

alpha &lt;-<span class="st"> </span>alpha_star <span class="op">-</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(x)
rhat &lt;-<span class="st"> </span>p <span class="op">*</span><span class="st"> </span>n</code></pre></div>
</div>
<div id="bugsjags-code-1" class="section level4">
<h4>BUGS/JAGS code</h4>
<div class="bugs">
<pre><code>for( i in 1 : N ) {
  r[i] ~ dbin(p[i],n[i])
  logit(p[i]) &lt;- alpha.star + beta * (x[i] - mean(x[]))
  rhat[i] &lt;- n[i] * p[i]
  culmative.r[i] &lt;- culmative(r[i], r[i])
}
alpha &lt;- alpha.star - beta * mean(x[])
beta ~ dnorm(0.0,0.001)
alpha.star ~ dnorm(0.0,0.001)</code></pre>
</div>
</div>
<div id="stan-code-1" class="section level4">
<h4>Stan code</h4>
<div class="stan">
<pre><code>data {
    int&lt;lower=0&gt; N;
    int&lt;lower=0&gt; n[N];
    int&lt;lower=0&gt; r[N];
    vector[N] x;
}

transformed data {
    vector[N] centered_x;
    real mean_x;
    mean_x &lt;- mean(x);
    centered_x &lt;- x - mean_x;
}

parameters {
    real alpha_star;
    real beta;
}

transformed parameters {
    vector[N] m;
    m &lt;- alpha_star + beta * centered_x;
}

model {
  alpha_star ~ normal(0.0, 1.0E4);  
  beta ~ normal(0.0, 1.0E4);
  r ~ binomial_logit(n, m);
}

generated quantities {
  real alpha; 
  real p[N];
  real llike[N];
  real rhat[N];
  for (i in 1:N)  {
    p[i] &lt;- inv_logit(m[i]);
    llike[i]  &lt;- r[i]*log(p[i]) + (n[i]-r[i])*log(1-p[i]);  
    rhat[i] &lt;- p[i]*n[i];  // fitted values
  }
  alpha &lt;- alpha_star - beta*mean_x;              
} </code></pre>
</div>
</div>
</div>
</div>
<div id="stan-models" class="section level2">
<h2>Stan models</h2>
<p>The following few code examples show how Stan code can be translated in equivalent greta models.</p>
<hr>
<div id="lightspeed" class="section level3">
<h3>Lightspeed</h3>
<p><em>Lightspeed</em> estimates a linear normal model without predictors. The data are 66 measurements from Simon Newcomb and represent the time required for light to travel roughly 7500 meters.</p>
<p>See also the <a href="https://github.com/stan-dev/example-models/wiki/ARM-Models-Sorted-by-Type#no-predictors">Stan examples</a> for details.</p>
<div id="data-2" class="section level4">
<h4>data</h4>
<pre class="text"><code>y &lt;- c(28, 26, 33, 24, 34, -44, 27, 16, 40, -2, 29, 22, 24, 21, 25, 
       30, 23, 29, 31, 19, 24, 20, 36, 32, 36, 28, 25, 21, 28, 29, 
       37, 25, 28, 26, 30, 32, 36, 26, 30, 22, 36, 23, 27, 27, 28, 
       27, 31, 27, 26, 33, 26, 32, 32, 24, 39, 28, 24, 25, 32, 25, 
       29, 27, 28, 29, 16, 23)
n &lt;- length(y)</code></pre>
</div>
<div id="greta-code-2" class="section level4">
<h4>greta code</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta  &lt;-<span class="st"> </span><span class="kw">variable</span>()
sigma &lt;-<span class="st"> </span><span class="kw">variable</span>(<span class="dt">lower =</span> <span class="dv">0</span>)

<span class="kw">distribution</span>(y) &lt;-<span class="st"> </span><span class="kw">normal</span>(beta, sigma)</code></pre></div>
</div>
<div id="stan-code-2" class="section level4">
<h4>Stan code</h4>
<div class="stan">
<pre><code>data {
  int&lt;lower=0&gt; N; 
  vector[N] y;
}
parameters {
  vector[1] beta;
  real&lt;lower=0&gt; sigma;
} 
model {
  y ~ normal(beta[1],sigma);
}</code></pre>
</div>
<hr>
</div>
</div>
<div id="eight-schools" class="section level3">
<h3>Eight schools</h3>
<p><em>Eight schools</em> estimates the effect of coaching programs in eight schools. The data are 8 measurements of coaching effects along with their standard errors.</p>
<p>See also the <a href="https://github.com/stan-dev/example-models/wiki/ARM-Models-Sorted-by-Type#varying-intercept">Stan example</a> for details.</p>
<div id="data-3" class="section level4">
<h4>data</h4>
<pre class="text"><code>y &lt;- c(28,  8, -3,  7, -1,  1, 18, 12)
sigma_y &lt;- c(15, 10, 16, 11,  9, 11, 10, 18)
N  &lt;- length(y)</code></pre>
</div>
<div id="greta-code-3" class="section level4">
<h4>greta code</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sigma_eta &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)
eta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, sigma_eta, <span class="dt">dim=</span>N)

mu_theta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>)
xi &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>)
theta &lt;-<span class="st"> </span>mu_theta <span class="op">+</span><span class="st"> </span>xi <span class="op">*</span><span class="st"> </span>eta

<span class="kw">distribution</span>(y) &lt;-<span class="st"> </span><span class="kw">normal</span>(theta, sigma_y)</code></pre></div>
</div>
<div id="stan-code-3" class="section level4">
<h4>Stan code</h4>
<div class="stan">
<pre><code>data {
  int&lt;lower=0&gt; N;
  vector[N] y;
  vector[N] sigma_y;
} 
parameters {
  vector[N] eta;
  real mu_theta;
  real&lt;lower=0,upper=100&gt; sigma_eta;
  real xi;
} 
transformed parameters {
  real&lt;lower=0&gt; sigma_theta;
  vector[N] theta;

  theta = mu_theta + xi * eta;
  sigma_theta = fabs(xi) / sigma_eta;
}
model {
  mu_theta ~ normal(0, 100);
  sigma_eta ~ inv_gamma(1, 1); //prior distribution can be changed to uniform

  eta ~ normal(0, sigma_eta);
  xi ~ normal(0, 5);
  y ~ normal(theta,sigma_y);
}</code></pre>
</div>
</div>
</div>
</div>
<div id="ecological-models" class="section level2">
<h2>Ecological models</h2>
<p>Here we provide some examples of common ecological models. We begin with a basic logistic regression often used in species distribution modelling to estimate species probability of presence. We then provide increasingly complex species distribution models, beginning with modelling observation error directly, and moving on to models for multiple species: independently but concurrently modelled species, partially pooled coefficients, repeated measures, and sub-models.</p>
<hr>
<div id="logistic-regression" class="section level3">
<h3>Logistic regression</h3>
<p>A simple logistic regression being to estimate the probability of species presence along a number of environmental gradients.</p>
<div id="data-4" class="section level4">
<h4>data</h4>
<pre class="text"><code># make fake data
n_env &lt;- 3
n_sites &lt;- 20

# n_sites x n_env matrix of environmental variables
env &lt;- matrix(rnorm(n_sites * n_env), nrow = n_sites) 
# n_sites observations of species presence or absence
occupancy &lt;- rbinom(n_sites, 1, 0.5) </code></pre>
</div>
<div id="greta-code-4" class="section level4">
<h4>greta code</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alpha &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
beta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_env)

<span class="co"># logit-linear model</span>
linear_predictor &lt;-<span class="st"> </span>alpha <span class="op">+</span><span class="st"> </span>env <span class="op">%*%</span><span class="st"> </span>beta
p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(linear_predictor)

<span class="co"># distribution (likelihood) over observed values</span>
<span class="kw">distribution</span>(occupancy) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(p)</code></pre></div>
<hr>
</div>
</div>
<div id="poisson-regression" class="section level3">
<h3>Poisson regression</h3>
<p>An example of a simple poisson regression being used to estimate the abundance of a species along a number of environmental gradients.</p>
<div id="data-5" class="section level4">
<h4>data</h4>
<pre class="text"><code># make fake data
n_env &lt;- 3
n_sites &lt;- 20

# n_sites x n_env matrix of environmental variables
env &lt;- matrix(rnorm(n_sites * n_env), nrow = n_sites) 
# n_sites observations of species abundance
occupancy &lt;- rpois(n_sites, 5) </code></pre>
</div>
<div id="greta-code-5" class="section level4">
<h4>greta code</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alpha &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
beta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_env)
linear_predictor &lt;-<span class="st"> </span>alpha <span class="op">+</span><span class="st"> </span>env <span class="op">%*%</span><span class="st"> </span>beta
lambda &lt;-<span class="st"> </span><span class="kw">exp</span>(linear_predictor)
<span class="kw">distribution</span>(occupancy) &lt;-<span class="st"> </span><span class="kw">poisson</span>(lambda)</code></pre></div>
<hr>
</div>
</div>
<div id="logistic-regression-with-error-term" class="section level3">
<h3>Logistic regression with error term</h3>
<p>This is an example of a simple logistic regression with an extra observation-level error term, to model over-dispersion or clustering in occupancy data from multiple visits.</p>
<div id="data-6" class="section level4">
<h4>data</h4>
<pre class="text"><code># make fake data
n_env &lt;- 3
n_sites &lt;- 20
n_obs &lt;- 5

# n_sites x n_env matrix of environmental variables
env &lt;- matrix(rnorm(n_sites * n_env), nrow = n_sites) 
# n_sites observations of species presence or absence over n_obs visits
occupancy &lt;- rbinom(n_sites, n_obs, 0.5)</code></pre>
</div>
<div id="greta-code-6" class="section level4">
<h4>greta code</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alpha &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)
beta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_env)
error &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_sites)

<span class="co"># logit-linear model with extra variation</span>
linear_predictor &lt;-<span class="st"> </span>alpha <span class="op">+</span><span class="st"> </span>env <span class="op">%*%</span><span class="st"> </span>beta <span class="op">+</span><span class="st"> </span>error
p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(linear_predictor)

<span class="co"># distribution (likelihood) over observed values</span>
<span class="kw">distribution</span>(occupancy) &lt;-<span class="st"> </span><span class="kw">binomial</span>(n_obs, p)</code></pre></div>
<hr>
</div>
</div>
<div id="multiple-species-modelling-independently-and-concurrently" class="section level3">
<h3>Multiple species modelling independently and concurrently</h3>
<p>An example of a logistic regression being used to estimate the probability of multiple species’ presences along a number of environmental gradients. Although modelled concurrently, the random variables for each species are independent. We first simulate some data to model followed by the <code>greta</code> code.</p>
<p>Where a single observation per species and location would have a bernoulli error distribution, multiple observations for each species and location have a binomial distribution.</p>
<p>When modelling multiple species (or other grouping factor), we need an extra step in constructing the linear predictor. In order to add multiple <code>greta</code> arrays together <em>for each species</em> we can use the <code>sweep()</code> function.</p>
<div id="data-7" class="section level4">
<h4>data</h4>
<pre class="text"><code># make fake data
n_species &lt;- 5
n_env &lt;- 3
n_sites &lt;- 20

env &lt;- matrix(rnorm(n_sites * n_env), nrow = n_sites)
occupancy &lt;- matrix(rbinom(n_species * n_sites, 1, 0.5), nrow = n_sites)</code></pre>
</div>
<div id="greta-code-7" class="section level4">
<h4>greta code</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alpha &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_species)
beta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> <span class="kw">c</span>(n_env, n_species))

env_effect &lt;-<span class="st"> </span>env <span class="op">%*%</span><span class="st"> </span>beta

<span class="co"># add intercepts for all species</span>
linear_predictor &lt;-<span class="st"> </span><span class="kw">sweep</span>(env_effect, <span class="dv">2</span>, alpha, <span class="dt">FUN =</span> <span class="st">'+'</span>)

<span class="co"># ilogit of linear predictor</span>
p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(linear_predictor)

<span class="co"># a single observation means our data are bernoulli distributed</span>
<span class="kw">distribution</span>(occupancy) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(p)</code></pre></div>
<hr>
</div>
</div>
<div id="multiple-species-with-partial-pooling-of-regression-coefficients" class="section level3">
<h3>Multiple species with partial pooling of regression coefficients</h3>
<p>An example of a logistic regression being used to estimate the probability of multiple species’ presences along a number of environmental gradients. Instead of assuming independence of species regression coefficients, we assume they are drawn from a shared distribution. We partially pool species responses. This gives us not ony the regression coefficients for each species but also a global average coefficient and a measure of variation between species responses to environmental gradients.</p>
<div id="data-8" class="section level4">
<h4>data</h4>
<pre class="text"><code># make fake data
n_species &lt;- 5
n_env &lt;- 1
n_sites &lt;- 50

env &lt;- matrix(rnorm(n_sites * n_env), nrow = n_sites)
occupancy &lt;- matrix(rbinom(n_sites * n_species, 1, 0.5), nrow = n_sites)</code></pre>
</div>
<div id="greta-code-8" class="section level4">
<h4>greta code</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">global_alpha &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> <span class="dv">1</span>)
global_alpha_sd &lt;-<span class="st"> </span><span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> <span class="dv">1</span>) 
alpha &lt;-<span class="st"> </span><span class="kw">normal</span>(global_alpha, global_alpha_sd, <span class="dt">dim =</span> n_species)

global_betas &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_env)
global_betas_sd &lt;-<span class="st"> </span><span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_env)
beta &lt;-<span class="st"> </span><span class="kw">normal</span>(global_betas, global_betas_sd, <span class="dt">dim =</span> <span class="kw">c</span>(n_env, n_species))

env_effect &lt;-<span class="st"> </span>env <span class="op">%*%</span><span class="st"> </span>beta

<span class="co"># add intercepts for all species</span>
linear_predictor &lt;-<span class="st"> </span><span class="kw">sweep</span>(env_effect, <span class="dv">2</span>, alpha, <span class="dt">FUN =</span> <span class="st">'+'</span>)

<span class="co"># ilogit of linear predictor</span>
p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(linear_predictor)

<span class="kw">distribution</span>(occupancy) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(p)</code></pre></div>
<hr>
</div>
</div>
<div id="multiple-species-with-sub-model-for-regression-coefficients" class="section level3">
<h3>Multiple species with sub-model for regression coefficients</h3>
<p>An example of a logistic regression being used to estimate the probability of multiple species’ presences along a number of environmental gradients. Instead of assuming independence of species regression coefficients, or partial pooling in shared distributions, we use a sub-model to estimate species regression coefficients. In this case, we’re using species traits to estimate their response to different environmental gradients.</p>
<p>Because we’re building a sub-model, it’s more efficient to simply add a column of ones to dataframes for the base model and sub-model. This is simply to prevent our code from becoming too cumbersome. If we didn’t want to use our sub-model to estimate the intercept, we would not need to include the column of ones in the environmental dataframe.</p>
<div id="data-9" class="section level4">
<h4>data</h4>
<pre class="text"><code># make fake data
n_species &lt;- 3
n_env &lt;- 1
n_sites &lt;- 5
n_traits &lt;- 1

# n_sites x n_env matrix of environmental variables
env &lt;- matrix(rnorm(n_sites * n_env), nrow = n_sites)
# n_species * n_traits matix of trait variables
traits &lt;- matrix(rnorm(n_species * n_traits), nrow = n_species)
# n_sites * n_species matrix of observed occupancy
occupancy &lt;- matrix(rbinom(n_sites * n_species, 1, 0.5), nrow = n_sites)</code></pre>
</div>
<div id="greta-code-9" class="section level4">
<h4>greta code</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># include a column of 1's for intercept estimation in the sub-model (traits) and base model</span>
traits &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">rep</span>(<span class="dv">1</span>, n_species), traits)
env &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">rep</span>(<span class="dv">1</span>, n_sites), env)

<span class="co"># redefine n_env and n_traits after adding columns for intercepts</span>
n_env &lt;-<span class="st"> </span><span class="kw">ncol</span>(env)
n_traits &lt;-<span class="st"> </span><span class="kw">ncol</span>(traits)

<span class="co"># sub-model parameters have normal prior distributions</span>
g &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> <span class="kw">c</span>(n_env, n_traits))
<span class="co"># parameters of the base model are a function of the parameters of the sub-model</span>
beta &lt;-<span class="st">  </span>g <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(traits) 

<span class="co"># use the coefficients to get the model linear predictor</span>
linear_predictor &lt;-<span class="st"> </span>env <span class="op">%*%</span><span class="st"> </span>beta 

<span class="co"># use the logit link to get probabilities of occupancy</span>
p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(linear_predictor)

<span class="co"># data are bernoulli distributed</span>
<span class="kw">distribution</span>(occupancy) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(p)</code></pre></div>
<hr>
</div>
</div>
<div id="cormack-jolly-seber-model" class="section level3">
<h3>Cormack-Jolly-Seber model</h3>
<p><em>Cormack-Jolly-Seber</em> (CJS) models estimate probabilities of survival and recapture from mark-recapture data. These models assume that we can only ever see individuals that have been initially marked and released or recaptured following release (i.e. individuals do not exist until first observed). The two key parameters are survival, <span class="math inline">\(\phi\)</span>, and probability of recapture, <span class="math inline">\(p\)</span>. There is an additional derived parameter, <span class="math inline">\(\chi\)</span>, which is the probability that an individual is not recaptured following its final capture. <span class="math inline">\(\chi\)</span> marginalises over multiple scenarios in which the individual is not observed either because it has died or because it is alive but not detected.</p>
<p>The <a href="http://www.phidot.org/software/mark/docs/book/">introductory book</a> to the program MARK has a lot of information on mark-recapture models, including CJS models (starting in Ch. 1) and the broader class of Jolly-Seber models (Ch. 12). There is also a section on mark-recapture models in the <a href="http://mc-stan.org/users/documentation/">Stan language manual</a>, which goes through the derivation of the parameter <span class="math inline">\(\chi\)</span>.</p>
<div id="data-10" class="section level4">
<h4>data</h4>
<div class="data">
<pre class="text"><code>n_obs &lt;- 100
n_time &lt;- 20
y &lt;- matrix(sample(c(0, 1), size = (n_obs * n_time), replace = TRUE),
            ncol = n_time)</code></pre>
</div>
</div>
<div id="greta-code-10" class="section level4">
<h4>greta code</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># data summaries</span>
first_obs &lt;-<span class="st"> </span><span class="kw">apply</span>(y, <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="kw">min</span>(<span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)))
final_obs &lt;-<span class="st"> </span><span class="kw">apply</span>(y, <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="kw">max</span>(<span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)))
obs_id &lt;-<span class="st"> </span><span class="kw">apply</span>(y, <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="kw">seq</span>(<span class="kw">min</span>(<span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)), <span class="kw">max</span>(<span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)), <span class="dt">by =</span> <span class="dv">1</span>)[<span class="op">-</span><span class="dv">1</span>])
obs_id &lt;-<span class="st"> </span><span class="kw">unlist</span>(obs_id)
capture_vec &lt;-<span class="st"> </span><span class="kw">apply</span>(y, <span class="dv">1</span>, <span class="cf">function</span>(x) x[<span class="kw">min</span>(<span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>))<span class="op">:</span><span class="kw">max</span>(<span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>))][<span class="op">-</span><span class="dv">1</span>])
capture_vec &lt;-<span class="st"> </span><span class="kw">unlist</span>(capture_vec)

<span class="co"># priors</span>
phi &lt;-<span class="st"> </span><span class="kw">beta</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dt">dim =</span> n_time)
p &lt;-<span class="st"> </span><span class="kw">beta</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dt">dim =</span> n_time)

<span class="co"># derived parameter</span>
chi &lt;-<span class="st"> </span><span class="kw">ones</span>(n_time)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_len</span>(n_time <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) {
  tn &lt;-<span class="st"> </span>n_time <span class="op">-</span><span class="st"> </span>i
  chi[tn] &lt;-<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>phi[tn]) <span class="op">+</span><span class="st"> </span>phi[tn] <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p[tn <span class="op">+</span><span class="st"> </span><span class="dv">1</span>]) <span class="op">*</span><span class="st"> </span>chi[tn <span class="op">+</span><span class="st"> </span><span class="dv">1</span>]
}

<span class="co"># dummy variables</span>
alive_data &lt;-<span class="st"> </span><span class="kw">ones</span>(<span class="kw">length</span>(obs_id))            <span class="co"># definitely alive</span>
not_seen_last &lt;-<span class="st"> </span>final_obs <span class="op">!=</span><span class="st"> </span><span class="dv">20</span>              <span class="co"># ignore observations in last timestep</span>
final_observation &lt;-<span class="st"> </span><span class="kw">ones</span>(<span class="kw">sum</span>(not_seen_last)) <span class="co"># final observation</span>

<span class="co"># set likelihoods</span>
<span class="kw">distribution</span>(alive_data) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(phi[obs_id <span class="op">-</span><span class="st"> </span><span class="dv">1</span>])
<span class="kw">distribution</span>(capture_vec) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(p[obs_id])
<span class="kw">distribution</span>(final_observation) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(chi[final_obs[not_seen_last]])</code></pre></div>
</div>
<div id="bugsjags-code-2" class="section level4">
<h4>BUGS/JAGS code</h4>
<div class="bugs">
<pre><code>model {
  # priors
  for (t in 1:(n_time - 1)) {
    phi[t] ~ dunif(0, 1)
    p[t] ~ dunif(0, 1)
  }
  # likelihood
  for (i in 1:n_obs) {
    z[i, first_obs[i]] &lt;- 1   # state at first capture must be 1!
    for (t in (first_obs[i] + 1):n_time) {
      mu1[i, t] &lt;- phi[t - 1] * z[i, t - 1] 
      z[i, t] ~ dbern(mu1[i, t])   # true state
      mu2[i, t] &lt;- p[t - 1] * z[i, t]
      y[i, t] ~ dbern(mu2[i, t])      # observed state
    }
  }
}</code></pre>
</div>
</div>
<div id="stan-code-4" class="section level4">
<h4>Stan code</h4>
<div class="stan">
<pre><code>/**
 * Cormack-Jolly-Seber Model
 * 
 * following section 1.2.1 of:
 * http://www.maths.otago.ac.nz/home/resources/theses/PhD_Matthew_Schofield.pdf
 *
 */
data {
  int&lt;lower=2&gt; K;                      // capture events
  int&lt;lower=0&gt; I;                      // number of individuals
  int&lt;lower=0,upper=1&gt; X[I,K];         // X[i,k]: individual i captured at k
}
transformed data {
  int&lt;lower=0,upper=K+1&gt; first[I];     // first[i]: ind i first capture
  int&lt;lower=0,upper=K+1&gt; last[I];      // last[i]:  ind i last capture
  int&lt;lower=0,upper=I&gt; n_captured[K];  // n_capt[k]: num aptured at k

  first &lt;- rep_array(K+1,I);
  last &lt;- rep_array(0,I);
  for (i in 1:I) {
    for (k in 1:K) {
      if (X[i,k] == 1) {
        if (k &lt; first[i]) 
          first[i] &lt;- k;
        if (k &gt; last[i]) 
          last[i] &lt;- k;
      }
    }
  }

  n_captured &lt;- rep_array(0,K);
  for (i in 1:I)
    for (k in 1:K)
      n_captured[k] &lt;- n_captured[k] + X[i,k];
}
parameters {
  vector&lt;lower=0,upper=1&gt;[K-1] phi;  // phi[k]: Pr[alive at k + 1 | alive at k]
  vector&lt;lower=0,upper=1&gt;[K] p;      // p[k]: Pr[capture at k]

  // note:  p[1] not used in model and hence not identified
}
transformed parameters {
  vector&lt;lower=0,upper=1&gt;[K] chi;   // chi[k]: Pr[no capture &gt;  k | alive at k]
  {
    int k;
    chi[K] &lt;- 1.0;              
    k &lt;- K - 1;
    while (k &gt; 0) {
      chi[k] &lt;- (1 - phi[k]) + phi[k] * (1 - p[k+1]) * chi[k+1]; 
      k &lt;- k - 1;
    }
  }
}
model {
  for (i in 1:I) {
    if (last[i] &gt; 0) {
      for (k in (first[i]+1):last[i]) {
        increment_log_prob(log(phi[k-1]));     // i survived from k-1 to k
        if (X[i,k] == 1)
          increment_log_prob(log(p[k]));       // i captured at k
        else
          increment_log_prob(log1m(p[k]));     // i not captured at k
      }
      increment_log_prob(log(chi[last[i]]));   // i not seen after last[i]
    }
  }
}
generated quantities {
  // phi[K-1] and p(K) not identified, but product is
  real beta;
  vector&lt;lower=0&gt;[K] pop_hat;  // population

  beta &lt;- phi[K-1] * p[K];

  for (k in 1:K)
    pop_hat[k] &lt;- n_captured[k] / p[k];  
}</code></pre>
</div>
<hr>
</div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
