<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1">



<title>Example models</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#header {
text-align: center;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; }  code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Example models</h1>



<div id="common-models" class="section level2">
<h2>Common models</h2>
<p>Below are a few examples of common statistical models implemented in greta.</p>
<hr>
<div id="linear-regression" class="section level3">
<h3>Linear regression</h3>
<p>A simple, one-variable Bayesian linear regression model using the attitude data</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># variables &amp; priors</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>int &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb1-3"><a href="#cb1-3"></a>coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb1-4"><a href="#cb1-4"></a>sd &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))</span>
<span id="cb1-5"><a href="#cb1-5"></a></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="co"># linear predictor</span></span>
<span id="cb1-7"><a href="#cb1-7"></a>mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>attitude<span class="op">$</span>complaints</span>
<span id="cb1-8"><a href="#cb1-8"></a></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="co"># observation model</span></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</span></code></pre></div>
<hr>
</div>
<div id="multiple-linear-regression" class="section level3">
<h3>Multiple linear regression</h3>
<p>A multi-variable Bayesian linear regression model using the attitude data</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="kw">data</span>(attitude)</span>
<span id="cb2-2"><a href="#cb2-2"></a>design &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(attitude[, <span class="dv">2</span><span class="op">:</span><span class="dv">7</span>])</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a>int &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb3-2"><a href="#cb3-2"></a>coefs &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> <span class="kw">ncol</span>(design))</span>
<span id="cb3-3"><a href="#cb3-3"></a>sd &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))</span>
<span id="cb3-4"><a href="#cb3-4"></a></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="co"># matrix multiplication is more efficient than multiplying the coefficients</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="co"># separately</span></span>
<span id="cb3-7"><a href="#cb3-7"></a>mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>design <span class="op">%*%</span><span class="st"> </span>coefs</span>
<span id="cb3-8"><a href="#cb3-8"></a></span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</span></code></pre></div>
<hr>
</div>
<div id="multiple-poisson-regression" class="section level3">
<h3>Multiple Poisson regression</h3>
<p>A multiple Bayesian linear regression model using the <code>warpbreaks</code> data.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">data</span>(<span class="st">&quot;warpbreaks&quot;</span>)</span>
<span id="cb4-2"><a href="#cb4-2"></a>X &lt;-<span class="st"> </span><span class="kw">as_data</span>(<span class="kw">model.matrix</span>(breaks <span class="op">~</span><span class="st"> </span>wool <span class="op">+</span><span class="st"> </span>tension, warpbreaks))</span>
<span id="cb4-3"><a href="#cb4-3"></a>y &lt;-<span class="st"> </span><span class="kw">as_data</span>(warpbreaks<span class="op">$</span>breaks)</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a>int &lt;-<span class="st"> </span><span class="kw">variable</span>()</span>
<span id="cb5-2"><a href="#cb5-2"></a>coefs &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dt">dim =</span> <span class="kw">ncol</span>(X) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb5-3"><a href="#cb5-3"></a>beta &lt;-<span class="st"> </span><span class="kw">c</span>(int, coefs)</span>
<span id="cb5-4"><a href="#cb5-4"></a></span>
<span id="cb5-5"><a href="#cb5-5"></a>eta &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>beta</span>
<span id="cb5-6"><a href="#cb5-6"></a></span>
<span id="cb5-7"><a href="#cb5-7"></a><span class="kw">distribution</span>(y) &lt;-<span class="st"> </span><span class="kw">poisson</span>(<span class="kw">exp</span>(eta))</span></code></pre></div>
<hr>
</div>
<div id="multiple-categorical-regression" class="section level3">
<h3>Multiple categorical regression</h3>
<p>A multi-variable Bayesian categorical regression model using the iris data.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">data</span>(iris)</span>
<span id="cb6-2"><a href="#cb6-2"></a>X &lt;-<span class="st"> </span><span class="kw">as_data</span>(<span class="kw">cbind</span>(<span class="dv">1</span>, iris[, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>]))</span>
<span id="cb6-3"><a href="#cb6-3"></a>y &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="st"> </span>Species <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, iris)</span>
<span id="cb6-4"><a href="#cb6-4"></a>P &lt;-<span class="st"> </span><span class="kw">ncol</span>(X)</span>
<span id="cb6-5"><a href="#cb6-5"></a>K &lt;-<span class="st"> </span><span class="kw">ncol</span>(y)</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a>beta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dt">dim =</span> <span class="kw">c</span>(P, K <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))</span>
<span id="cb7-2"><a href="#cb7-2"></a>eta &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>beta</span>
<span id="cb7-3"><a href="#cb7-3"></a>prob &lt;-<span class="st"> </span><span class="kw">imultilogit</span>(eta)</span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="kw">distribution</span>(y) &lt;-<span class="st"> </span><span class="kw">categorical</span>(prob)</span></code></pre></div>
<hr>
</div>
<div id="multiple-linear-regression-with-lasso-prior" class="section level3">
<h3>Multiple linear regression with LASSO prior</h3>
<p>A multi-variable Bayesian linear regression model using an exponential-normal prior for the coefficients.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="kw">data</span>(attitude)</span>
<span id="cb8-2"><a href="#cb8-2"></a>design &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(attitude[, <span class="dv">2</span><span class="op">:</span><span class="dv">7</span>])</span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a>int &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb9-2"><a href="#cb9-2"></a>sd &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))</span>
<span id="cb9-3"><a href="#cb9-3"></a></span>
<span id="cb9-4"><a href="#cb9-4"></a>tau &lt;-<span class="st"> </span><span class="kw">exponential</span>(<span class="fl">0.5</span>, <span class="dt">dim =</span> <span class="kw">ncol</span>(design)) </span>
<span id="cb9-5"><a href="#cb9-5"></a>coefs &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, tau)</span>
<span id="cb9-6"><a href="#cb9-6"></a>mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>design <span class="op">%*%</span><span class="st"> </span>coefs</span>
<span id="cb9-7"><a href="#cb9-7"></a></span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</span></code></pre></div>
<hr>
</div>
<div id="hierarchical-linear-regression" class="section level3">
<h3>Hierarchical linear regression</h3>
<p>A hierarchical, Bayesian linear regression model using the iris data, with random intercepts for each of the three species.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># linear model parameters</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>int &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb10-3"><a href="#cb10-3"></a>coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb10-4"><a href="#cb10-4"></a>sd &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))</span>
<span id="cb10-5"><a href="#cb10-5"></a></span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="co"># hierarchical model for species effect; use the first species as the baseline</span></span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="co"># like in lm()</span></span>
<span id="cb10-8"><a href="#cb10-8"></a>species_sd &lt;-<span class="st"> </span><span class="kw">lognormal</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb10-9"><a href="#cb10-9"></a>species_offset &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, species_sd, <span class="dt">dim =</span> <span class="dv">2</span>)</span>
<span id="cb10-10"><a href="#cb10-10"></a>species_effect &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="dv">0</span>, species_offset)</span>
<span id="cb10-11"><a href="#cb10-11"></a>species_id &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(iris<span class="op">$</span>Species)</span>
<span id="cb10-12"><a href="#cb10-12"></a></span>
<span id="cb10-13"><a href="#cb10-13"></a><span class="co"># model</span></span>
<span id="cb10-14"><a href="#cb10-14"></a>mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>iris<span class="op">$</span>Sepal.Width <span class="op">+</span><span class="st"> </span>species_effect[species_id]</span>
<span id="cb10-15"><a href="#cb10-15"></a><span class="kw">distribution</span>(iris<span class="op">$</span>Sepal.Length) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</span></code></pre></div>
<hr>
</div>
<div id="random-intercept-slope-model" class="section level3">
<h3>Random intercept-slope model</h3>
<p>A hierarchical, Bayesian linear regression model using the iris data, with random intercepts and slopes for each of the three species. The slopes and intercepts for each species are <em>uncorrelated</em> in this example.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="co"># linear model parameters</span></span>
<span id="cb11-2"><a href="#cb11-2"></a>int &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb11-3"><a href="#cb11-3"></a>coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb11-4"><a href="#cb11-4"></a>sd &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))</span>
<span id="cb11-5"><a href="#cb11-5"></a></span>
<span id="cb11-6"><a href="#cb11-6"></a>species_id &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(iris<span class="op">$</span>Species)</span>
<span id="cb11-7"><a href="#cb11-7"></a></span>
<span id="cb11-8"><a href="#cb11-8"></a><span class="co"># random intercepts</span></span>
<span id="cb11-9"><a href="#cb11-9"></a>species_int_sd &lt;-<span class="st"> </span><span class="kw">lognormal</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb11-10"><a href="#cb11-10"></a>species_int &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, species_int_sd, <span class="dt">dim =</span> <span class="dv">2</span>)</span>
<span id="cb11-11"><a href="#cb11-11"></a>species_int_eff &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="dv">0</span>, species_int)</span>
<span id="cb11-12"><a href="#cb11-12"></a></span>
<span id="cb11-13"><a href="#cb11-13"></a><span class="co"># random slopes</span></span>
<span id="cb11-14"><a href="#cb11-14"></a>species_slope_sd &lt;-<span class="st"> </span><span class="kw">lognormal</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb11-15"><a href="#cb11-15"></a>species_slope &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, species_slope_sd, <span class="dt">dim =</span> <span class="dv">2</span>)</span>
<span id="cb11-16"><a href="#cb11-16"></a>species_slope_eff &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="dv">0</span>, species_slope)</span>
<span id="cb11-17"><a href="#cb11-17"></a></span>
<span id="cb11-18"><a href="#cb11-18"></a><span class="co"># model</span></span>
<span id="cb11-19"><a href="#cb11-19"></a>mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>iris<span class="op">$</span>Sepal.Width <span class="op">+</span><span class="st"> </span>species_int_eff[species_id] <span class="op">+</span><span class="st"> </span>iris<span class="op">$</span>Sepal.Width <span class="op">*</span><span class="st"> </span>species_slope_eff[species_id]</span>
<span id="cb11-20"><a href="#cb11-20"></a><span class="kw">distribution</span>(iris<span class="op">$</span>Sepal.Length) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</span></code></pre></div>
</div>
</div>
<div id="common-bayesian-priors" class="section level2">
<h2>Common Bayesian priors</h2>
<p>The following examples show some common Bayesian priors of which some induce sparsity.</p>
<hr>
<div id="improper-flat-prior" class="section level3">
<h3>Improper flat prior</h3>
<p>A simple, one-variable Bayesian linear regression model that uses flat priors for the coefficients. A flat prior using <code>variable</code> puts an unbounded uniform distribution on the parameter. With unconstrained flat priors, the posterior will be proportional to the likelihood and the MAP will correspond to the MLE. Flat priors are usually chosen when there is little knowledge about the parameters available.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a><span class="co"># variables &amp; priors</span></span>
<span id="cb12-2"><a href="#cb12-2"></a>int  &lt;-<span class="st"> </span><span class="kw">variable</span>()</span>
<span id="cb12-3"><a href="#cb12-3"></a>coef &lt;-<span class="st"> </span><span class="kw">variable</span>()</span>
<span id="cb12-4"><a href="#cb12-4"></a>sd   &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))</span>
<span id="cb12-5"><a href="#cb12-5"></a></span>
<span id="cb12-6"><a href="#cb12-6"></a><span class="co"># linear predictor</span></span>
<span id="cb12-7"><a href="#cb12-7"></a>mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>attitude<span class="op">$</span>complaints</span>
<span id="cb12-8"><a href="#cb12-8"></a></span>
<span id="cb12-9"><a href="#cb12-9"></a><span class="co"># observation model</span></span>
<span id="cb12-10"><a href="#cb12-10"></a><span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</span></code></pre></div>
<hr>
</div>
<div id="ridge-prior" class="section level3">
<h3>Ridge prior</h3>
<p>Here we estimate a simple, one-variable Bayesian linear regression model that uses a <em>ridge</em> prior. The ridge prior has a frequentist interpretation where it is used as a penalty for regression coefficients. Among other effects, the penalty shrinks the coefficients towards zero to reduce variance without setting them to zero. The Bayesian version uses a normal distribution for the slopes and a inverse gamma prior for the strength of the penalty. Note that since the prior in our intercept is still improper, the joint prior is also improper.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="co"># variables &amp; priors</span></span>
<span id="cb13-2"><a href="#cb13-2"></a>int &lt;-<span class="st"> </span><span class="kw">variable</span>()</span>
<span id="cb13-3"><a href="#cb13-3"></a>sd &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))</span>
<span id="cb13-4"><a href="#cb13-4"></a></span>
<span id="cb13-5"><a href="#cb13-5"></a>tau &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb13-6"><a href="#cb13-6"></a>coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, tau)</span>
<span id="cb13-7"><a href="#cb13-7"></a></span>
<span id="cb13-8"><a href="#cb13-8"></a><span class="co"># linear predictor</span></span>
<span id="cb13-9"><a href="#cb13-9"></a>mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>attitude<span class="op">$</span>complaints</span>
<span id="cb13-10"><a href="#cb13-10"></a></span>
<span id="cb13-11"><a href="#cb13-11"></a><span class="co"># observation model</span></span>
<span id="cb13-12"><a href="#cb13-12"></a><span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</span></code></pre></div>
<hr>
</div>
<div id="exponential-normal-prior" class="section level3">
<h3>Exponential-normal prior</h3>
<p>In this example we infer the parameters of one-variable Bayesian linear regression model using an exponential-normal prior. A compound exponential-normal prior can be interpreted like an equivalent to the frequentist LASSO. The exponential-normal prior yields a posterior that is pooled towards zero. An exponential-normal prior, or equivalently a Laplace prior, is consequently often chosen when a sparse solution is assumed, which, for instance, is a natural scenario in many biological settings.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a><span class="co"># variables &amp; priors</span></span>
<span id="cb14-2"><a href="#cb14-2"></a>int &lt;-<span class="st"> </span><span class="kw">variable</span>()</span>
<span id="cb14-3"><a href="#cb14-3"></a>sd &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb14-4"><a href="#cb14-4"></a></span>
<span id="cb14-5"><a href="#cb14-5"></a>lambda &lt;-<span class="st"> </span><span class="kw">gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb14-6"><a href="#cb14-6"></a>tau &lt;-<span class="st"> </span><span class="kw">exponential</span>(<span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>lambda<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb14-7"><a href="#cb14-7"></a>coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, tau)</span>
<span id="cb14-8"><a href="#cb14-8"></a></span>
<span id="cb14-9"><a href="#cb14-9"></a><span class="co"># linear predictor</span></span>
<span id="cb14-10"><a href="#cb14-10"></a>mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>attitude<span class="op">$</span>complaints</span>
<span id="cb14-11"><a href="#cb14-11"></a></span>
<span id="cb14-12"><a href="#cb14-12"></a><span class="co"># observation model</span></span>
<span id="cb14-13"><a href="#cb14-13"></a><span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</span></code></pre></div>
<hr>
</div>
<div id="horseshoe-prior" class="section level3">
<h3>Horseshoe prior</h3>
<p>A simple, one-variable Bayesian linear regression model using a horseshoe prior. The horseshoe, just as the LASSO, can be used when the slopes are assumed to be sparse. According to the original <a href="http://proceedings.mlr.press/v5/carvalho09a/carvalho09a.pdf">publication</a>: &gt; its flat, Cauchy-like tails allow strong signals to remain large […] &gt; a posteriori. Yet its infinitely tall spike at the origin provides &gt; severe shrinkage for the zero elements</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a>horseshoe &lt;-<span class="st"> </span><span class="cf">function</span> (<span class="dt">tau =</span> <span class="dv">1</span>, <span class="dt">dim =</span> <span class="ot">NULL</span>) {</span>
<span id="cb15-2"><a href="#cb15-2"></a>  lambda &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>), <span class="dt">dim =</span> dim)</span>
<span id="cb15-3"><a href="#cb15-3"></a>  sd &lt;-<span class="st"> </span>tau <span class="op">^</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>lambda <span class="op">^</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb15-4"><a href="#cb15-4"></a>  <span class="kw">normal</span>(<span class="dv">0</span>, sd, <span class="dt">dim =</span> dim)</span>
<span id="cb15-5"><a href="#cb15-5"></a>}</span>
<span id="cb15-6"><a href="#cb15-6"></a></span>
<span id="cb15-7"><a href="#cb15-7"></a><span class="co"># variables &amp; priors</span></span>
<span id="cb15-8"><a href="#cb15-8"></a>int &lt;-<span class="st"> </span><span class="kw">variable</span>()</span>
<span id="cb15-9"><a href="#cb15-9"></a>sd &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb15-10"><a href="#cb15-10"></a>coef &lt;-<span class="st"> </span><span class="kw">horseshoe</span>()</span>
<span id="cb15-11"><a href="#cb15-11"></a></span>
<span id="cb15-12"><a href="#cb15-12"></a><span class="co"># linear predictor</span></span>
<span id="cb15-13"><a href="#cb15-13"></a>mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>attitude<span class="op">$</span>complaints</span>
<span id="cb15-14"><a href="#cb15-14"></a></span>
<span id="cb15-15"><a href="#cb15-15"></a><span class="co"># observation model</span></span>
<span id="cb15-16"><a href="#cb15-16"></a><span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</span></code></pre></div>
<hr>
</div>
<div id="regularized-horseshoe-prior" class="section level3">
<h3>Regularized horseshoe prior</h3>
<p>The regularized (‘Finnish’) horseshoe (doi.org/10.1214/17-EJS1337SI) remedies a problem of the original horseshoe: large, unregularized values for the coefficients. This is especially problematic in scenarios where the parameters are only weakly identified by the data, as in logistic regression with perfectly seperable data.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>regularized_horseshoe &lt;-<span class="st"> </span><span class="cf">function</span> (<span class="dt">tau =</span> <span class="dv">1</span>,  <span class="dt">c =</span> <span class="dv">1</span>, <span class="dt">dim =</span> <span class="ot">NULL</span>) {</span>
<span id="cb16-2"><a href="#cb16-2"></a>  <span class="kw">stopifnot</span>(c <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)</span>
<span id="cb16-3"><a href="#cb16-3"></a>  lambda &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>), <span class="dt">dim =</span> dim)</span>
<span id="cb16-4"><a href="#cb16-4"></a>  lambda_tilde &lt;-<span class="st"> </span>(c<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>lambda<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>(c<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>lambda<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb16-5"><a href="#cb16-5"></a>  sd &lt;-<span class="st"> </span>tau <span class="op">^</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>lambda_tilde <span class="op">^</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb16-6"><a href="#cb16-6"></a>  <span class="kw">normal</span>(<span class="dv">0</span>, sd, <span class="dt">dim =</span> dim)</span>
<span id="cb16-7"><a href="#cb16-7"></a>}</span>
<span id="cb16-8"><a href="#cb16-8"></a></span>
<span id="cb16-9"><a href="#cb16-9"></a><span class="co"># variables &amp; priors</span></span>
<span id="cb16-10"><a href="#cb16-10"></a>int &lt;-<span class="st"> </span><span class="kw">variable</span>()</span>
<span id="cb16-11"><a href="#cb16-11"></a>sd &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb16-12"><a href="#cb16-12"></a>coef &lt;-<span class="st"> </span><span class="kw">regularized_horseshoe</span>()</span>
<span id="cb16-13"><a href="#cb16-13"></a></span>
<span id="cb16-14"><a href="#cb16-14"></a><span class="co"># linear predictor</span></span>
<span id="cb16-15"><a href="#cb16-15"></a>mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>attitude<span class="op">$</span>complaints</span>
<span id="cb16-16"><a href="#cb16-16"></a></span>
<span id="cb16-17"><a href="#cb16-17"></a><span class="co"># observation model</span></span>
<span id="cb16-18"><a href="#cb16-18"></a><span class="kw">distribution</span>(attitude<span class="op">$</span>rating) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</span></code></pre></div>
</div>
</div>
<div id="advanced-bayesian-models" class="section level2">
<h2>Advanced Bayesian models</h2>
<p>Below are some more advanced examples implemented in greta.</p>
<hr>
<div id="hierarchical-linear-regression-in-general-conditional-formulation" class="section level3">
<h3>Hierarchical linear regression in general conditional formulation</h3>
<p>A hierarchical, Bayesian linear regression model using the iris data, with random intercepts and slopes for each of the three species. The slopes and intercepts for each species are <em>correlated</em> in this example. We allow every species to have a species specific slope for <code>Sepal.Length</code>.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a>int  &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb17-2"><a href="#cb17-2"></a>coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb17-3"><a href="#cb17-3"></a>sd   &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))</span>
<span id="cb17-4"><a href="#cb17-4"></a></span>
<span id="cb17-5"><a href="#cb17-5"></a>n_species  &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(iris<span class="op">$</span>Species))</span>
<span id="cb17-6"><a href="#cb17-6"></a>species_id &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(iris<span class="op">$</span>Species)</span>
<span id="cb17-7"><a href="#cb17-7"></a></span>
<span id="cb17-8"><a href="#cb17-8"></a>Z &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="st"> </span>Species <span class="op">+</span><span class="st"> </span>Sepal.Length <span class="op">*</span><span class="st"> </span>Species <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> iris)</span>
<span id="cb17-9"><a href="#cb17-9"></a></span>
<span id="cb17-10"><a href="#cb17-10"></a>gamma_matrix &lt;-<span class="st"> </span><span class="kw">multivariate_normal</span>(<span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>),</span>
<span id="cb17-11"><a href="#cb17-11"></a>                                    <span class="kw">diag</span>(<span class="dv">2</span>),</span>
<span id="cb17-12"><a href="#cb17-12"></a>                                    <span class="dt">n_realisations =</span> <span class="dv">3</span>) </span>
<span id="cb17-13"><a href="#cb17-13"></a>gamma &lt;-<span class="st"> </span><span class="kw">c</span>(gamma_matrix)</span>
<span id="cb17-14"><a href="#cb17-14"></a></span>
<span id="cb17-15"><a href="#cb17-15"></a>wi &lt;-<span class="st"> </span><span class="kw">as_data</span>(iris<span class="op">$</span>Sepal.Width)</span>
<span id="cb17-16"><a href="#cb17-16"></a>Z  &lt;-<span class="st"> </span><span class="kw">as_data</span>(Z)</span>
<span id="cb17-17"><a href="#cb17-17"></a>mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>wi <span class="op">+</span><span class="st"> </span>Z <span class="op">%*%</span><span class="st"> </span>gamma</span>
<span id="cb17-18"><a href="#cb17-18"></a></span>
<span id="cb17-19"><a href="#cb17-19"></a><span class="kw">distribution</span>(iris<span class="op">$</span>Sepal.Length) &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sd)</span></code></pre></div>
<hr>
</div>
<div id="hierarchical-linear-regression-in-general-marginal-formulation" class="section level3">
<h3>Hierarchical linear regression in general marginal formulation</h3>
<p>A hierarchical, Bayesian linear regression model using the iris data, with random intercepts and slopes for each of the three species. This time we try to set up the <em>marginal</em> model, i.e. when we integrate the conditional density.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a>int  &lt;-<span class="st"> </span><span class="kw">variable</span>()</span>
<span id="cb18-2"><a href="#cb18-2"></a>coef &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>)</span>
<span id="cb18-3"><a href="#cb18-3"></a>sd   &lt;-<span class="st"> </span><span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">truncation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">Inf</span>))</span>
<span id="cb18-4"><a href="#cb18-4"></a></span>
<span id="cb18-5"><a href="#cb18-5"></a>n_species  &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(iris<span class="op">$</span>Species))</span>
<span id="cb18-6"><a href="#cb18-6"></a>species_id &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(iris<span class="op">$</span>Species)</span>
<span id="cb18-7"><a href="#cb18-7"></a></span>
<span id="cb18-8"><a href="#cb18-8"></a>Z &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="st"> </span>Species <span class="op">+</span><span class="st"> </span>Sepal.Length <span class="op">*</span><span class="st"> </span>Species <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> iris)</span>
<span id="cb18-9"><a href="#cb18-9"></a>G  &lt;-<span class="st"> </span><span class="kw">zeros</span>(n_species <span class="op">*</span><span class="st"> </span><span class="dv">2</span>, n_species <span class="op">*</span><span class="st"> </span><span class="dv">2</span>)</span>
<span id="cb18-10"><a href="#cb18-10"></a></span>
<span id="cb18-11"><a href="#cb18-11"></a><span class="cf">for</span> (s <span class="cf">in</span> <span class="kw">unique</span>(species_id)) {</span>
<span id="cb18-12"><a href="#cb18-12"></a>  G[<span class="kw">c</span>(s, s <span class="op">+</span><span class="st"> </span>n_species), <span class="kw">c</span>(s, s <span class="op">+</span><span class="st"> </span>n_species)] &lt;-<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>)</span>
<span id="cb18-13"><a href="#cb18-13"></a>}</span>
<span id="cb18-14"><a href="#cb18-14"></a></span>
<span id="cb18-15"><a href="#cb18-15"></a>mu &lt;-<span class="st"> </span>int <span class="op">+</span><span class="st"> </span>coef <span class="op">*</span><span class="st"> </span>iris<span class="op">$</span>Sepal.Width</span>
<span id="cb18-16"><a href="#cb18-16"></a>V &lt;-<span class="st"> </span><span class="kw">zeros</span>(<span class="kw">nrow</span>(iris), <span class="kw">nrow</span>(iris))</span>
<span id="cb18-17"><a href="#cb18-17"></a><span class="kw">diag</span>(V) &lt;-<span class="st"> </span>sd</span>
<span id="cb18-18"><a href="#cb18-18"></a></span>
<span id="cb18-19"><a href="#cb18-19"></a>Z &lt;-<span class="st"> </span><span class="kw">as_data</span>(Z)</span>
<span id="cb18-20"><a href="#cb18-20"></a>V &lt;-<span class="st"> </span>V <span class="op">+</span><span class="st"> </span>Z <span class="op">%*%</span><span class="st"> </span>G <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(Z)</span>
<span id="cb18-21"><a href="#cb18-21"></a></span>
<span id="cb18-22"><a href="#cb18-22"></a>sep &lt;-<span class="st"> </span><span class="kw">t</span>(iris<span class="op">$</span>Sepal.Width)</span>
<span id="cb18-23"><a href="#cb18-23"></a><span class="kw">distribution</span>(sep) &lt;-<span class="st"> </span><span class="kw">multivariate_normal</span>(<span class="kw">t</span>(mu), V)</span></code></pre></div>
<hr>
</div>
<div id="bayesian-neural-network" class="section level3">
<h3>Bayesian neural network</h3>
<p><em>Bayesian neural network</em> estimates an easy neural network with a normal prior on the edge weights. For clarity we use an architecture without a hidden layer, such that the weights actually correspond to coefficients in a linear regression model.</p>
<pre class="text"><code>N &lt;- 100
p &lt;- 10

set.seed(23)  
X &lt;- matrix(rnorm(N * p), N)
beta &lt;- rnorm(10)
y &lt;- X %*% beta + rnorm(N, sd = 0.1)</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a>neural_network &lt;-<span class="st"> </span><span class="cf">function</span>(x)</span>
<span id="cb20-2"><a href="#cb20-2"></a>{</span>
<span id="cb20-3"><a href="#cb20-3"></a>  <span class="co"># this can be arbitrarily complex, e.g. multiple hidden layers</span></span>
<span id="cb20-4"><a href="#cb20-4"></a>  x <span class="op">%*%</span><span class="st"> </span>weights</span>
<span id="cb20-5"><a href="#cb20-5"></a>}</span>
<span id="cb20-6"><a href="#cb20-6"></a>  </span>
<span id="cb20-7"><a href="#cb20-7"></a>weights &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">dim =</span> <span class="kw">c</span>(p, <span class="dv">1</span>))</span>
<span id="cb20-8"><a href="#cb20-8"></a>sd &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb20-9"><a href="#cb20-9"></a></span>
<span id="cb20-10"><a href="#cb20-10"></a><span class="kw">distribution</span>(y) &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="kw">neural_network</span>(X), sd)</span></code></pre></div>
<hr>
</div>
<div id="factor-analysis" class="section level3">
<h3>Factor analysis</h3>
<p>Factor analysis is a linear latent model used for finding a lower-dimensional probabilistic description of a data set with observations <span class="math inline">\(\mathbf{x}_i \in \mathbb{R}^p\)</span>. We assume the data are generated according to <span class="math display">\[
\mathbf{x}_i = \mathbf{W} \mathbf{z}_i + \boldsymbol \mu + \epsilon_i
\]</span> where the noise <span class="math inline">\(\epsilon\)</span> is normally distributed with zero mean and diagonal covariance matrix <span class="math inline">\(\Psi = \mathrm{diag}(\psi_1, \dots, \psi_p)\)</span>. The goal of factor analysis is to estimate the latent variables <span class="math inline">\(\mathbf{z}_i \mathbb{R}^q\)</span>.</p>
<p>In this example we take the mean vector <span class="math inline">\(\boldsymbol \mu\)</span> to be zero.</p>
<div class="data">
<pre class="text"><code>generate.data &lt;- function(n = 100, p = 5, q = 2, psi = diag(rgamma(p, 1, 1)))
{
  W  &lt;- matrix(rnorm(p * q, 1), p, q)
  Z  &lt;- matrix(rnorm(q * n, 2), q, n)
  WZ &lt;- W %*% Z
  
  X  &lt;- matrix(0, n, p)
  for (i in seq_len(n)) {
    X[i, ] &lt;- MASS::mvrnorm(1, WZ[, i], psi)
  }
  
  list(X = X, W = W, Z = Z, psi = psi)
}

n &lt;- 100
p &lt;- 5
q &lt;- 2
data &lt;- generate.data(n = n, p = p, q = q)
X &lt;- data$X</code></pre>
</div>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a>W &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">dim =</span> <span class="kw">c</span>(p, q))</span>
<span id="cb22-2"><a href="#cb22-2"></a>Z &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">dim =</span> <span class="kw">c</span>(q, n))</span>
<span id="cb22-3"><a href="#cb22-3"></a>psi &lt;-<span class="st"> </span><span class="kw">zeros</span>(p, p)</span>
<span id="cb22-4"><a href="#cb22-4"></a><span class="kw">diag</span>(psi) &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dt">dim =</span> p)</span>
<span id="cb22-5"><a href="#cb22-5"></a></span>
<span id="cb22-6"><a href="#cb22-6"></a><span class="kw">distribution</span>(X) &lt;-<span class="st"> </span><span class="kw">multivariate_normal</span>(<span class="kw">t</span>(W <span class="op">%*%</span><span class="st"> </span>Z), psi)</span></code></pre></div>
</div>
</div>
<div id="bugs-models" class="section level2">
<h2>BUGS models</h2>
<p>The BUGS project provide a number of example models written in the BUGS modelling language. These models will run in WinBUGS and OpenBUGS, and likely also in JAGS. The <a href="https://github.com/stan-dev/example-models/wiki/BUGS-Examples-Sorted-Alphabetically">Stan wiki</a> provides Stan implementations of these models.</p>
<p>The following sections provide greta implementations of some of these example models, alongside the BUGS code from <a href="https://www.mrc-bsu.cam.ac.uk/wp-content/uploads/WinBUGS_Vol2.pdf">WinBUGS examples volume 2</a> (pdf) and Stan code and an R version of the data from the <a href="https://github.com/stan-dev/example-models/wiki">Stan example models wiki</a>.</p>
<hr>
<div id="air" class="section level3">
<h3>Air</h3>
<p><em>Air</em> analyses reported respiratory illness versus exposure to nitrogen dioxide in 103 children. The parameters <code>alpha</code>, <code>beta</code> and <code>sigma2</code> are known in advance, and the data are grouped into three categories.</p>
<p>See <a href="https://www.mrc-bsu.cam.ac.uk/wp-content/uploads/WinBUGS_Vol2.pdf">WinBUGS examples volume 2</a> (pdf) for details.</p>
<div id="data" class="section level4">
<h4>data</h4>
<pre class="text"><code>y &lt;- c(21, 20, 15)
n &lt;- c(48, 34, 21)
Z &lt;- c(10, 30, 50)
alpha &lt;- 4.48
beta &lt;- 0.76
sigma2 &lt;- 81.14
sigma &lt;- sqrt(sigma2)
tau &lt;- 1 / sigma2
J &lt;- 3</code></pre>
</div>
<div id="greta-code" class="section level4">
<h4>greta code</h4>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1"></a>theta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">32</span>, <span class="dt">dim =</span> <span class="dv">2</span>)</span>
<span id="cb24-2"><a href="#cb24-2"></a>mu &lt;-<span class="st"> </span>alpha <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>Z</span>
<span id="cb24-3"><a href="#cb24-3"></a>X &lt;-<span class="st"> </span><span class="kw">normal</span>(mu, sigma)</span>
<span id="cb24-4"><a href="#cb24-4"></a>p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(theta[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>theta[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>X)</span>
<span id="cb24-5"><a href="#cb24-5"></a><span class="kw">distribution</span>(y) &lt;-<span class="st"> </span><span class="kw">binomial</span>(n, p)</span></code></pre></div>
</div>
<div id="bugsjags-code" class="section level4">
<h4>BUGS/JAGS code</h4>
<div class="bugs">
<pre><code>for(j in 1 : J) {
   y[j] ~ dbin(p[j], n[j])
   logit(p[j]) &lt;- theta[1] + theta[2] * X[j]
   X[j] ~ dnorm(mu[j], tau)
   mu[j] &lt;- alpha + beta * Z[j]
}
theta[1] ~ dnorm(0.0, 0.001)
theta[2] ~ dnorm(0.0, 0.001)</code></pre>
</div>
</div>
<div id="stan-code" class="section level4">
<h4>Stan code</h4>
<div class="stan">
<pre><code>data {
  real alpha; 
  real beta; 
  real&lt;lower=0&gt; sigma2; 
  int&lt;lower=0&gt; J; 
  int y[J]; 
  vector[J] Z;
  int n[J]; 
} 

transformed data {
  real&lt;lower=0&gt; sigma; 
  sigma &lt;- sqrt(sigma2); 
} 

parameters {
   real theta1; 
   real theta2; 
   vector[J] X; 
} 

model {
  real p[J];
  theta1 ~ normal(0, 32);   // 32^2 = 1024 
  theta2 ~ normal(0, 32); 
  X ~ normal(alpha + beta * Z, sigma);
  y ~ binomial_logit(n, theta1 + theta2 * X);
}</code></pre>
</div>
<hr>
</div>
</div>
<div id="beetles" class="section level3">
<h3>Beetles</h3>
<p><em>Beetles</em> considers dose-response data from an experiment applying carbon disulphide to 8 beetles. The original example compares three different link functions; the logit, probit and complementary log-log. Here, only the code for the logit link is shown. You can implement the other two link functions in greta by changing <code>ilogit</code> to <code>iprobit</code> or <code>icloglog</code>.</p>
<p>See <a href="https://www.mrc-bsu.cam.ac.uk/wp-content/uploads/WinBUGS_Vol2.pdf">WinBUGS examples volume 2</a> (pdf) for details.</p>
<div id="data-1" class="section level4">
<h4>data</h4>
<pre class="text"><code>x &lt;- c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839)
n &lt;- c(59, 60, 62, 56, 63, 59, 62, 60)
r &lt;- c(6, 13, 18, 28, 52, 53, 61, 60)
N &lt;- 8</code></pre>
</div>
<div id="greta-code-1" class="section level4">
<h4>greta code</h4>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a>alpha_star &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">32</span>)</span>
<span id="cb28-2"><a href="#cb28-2"></a>beta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">32</span>)</span>
<span id="cb28-3"><a href="#cb28-3"></a>p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(alpha_star <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>(x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x)))</span>
<span id="cb28-4"><a href="#cb28-4"></a><span class="kw">distribution</span>(r) &lt;-<span class="st"> </span><span class="kw">binomial</span>(n, p)</span>
<span id="cb28-5"><a href="#cb28-5"></a></span>
<span id="cb28-6"><a href="#cb28-6"></a>alpha &lt;-<span class="st"> </span>alpha_star <span class="op">-</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(x)</span>
<span id="cb28-7"><a href="#cb28-7"></a>rhat &lt;-<span class="st"> </span>p <span class="op">*</span><span class="st"> </span>n</span></code></pre></div>
</div>
<div id="bugsjags-code-1" class="section level4">
<h4>BUGS/JAGS code</h4>
<div class="bugs">
<pre><code>for( i in 1 : N ) {
  r[i] ~ dbin(p[i],n[i])
  logit(p[i]) &lt;- alpha.star + beta * (x[i] - mean(x[]))
  rhat[i] &lt;- n[i] * p[i]
  culmative.r[i] &lt;- culmative(r[i], r[i])
}
alpha &lt;- alpha.star - beta * mean(x[])
beta ~ dnorm(0.0,0.001)
alpha.star ~ dnorm(0.0,0.001)</code></pre>
</div>
</div>
<div id="stan-code-1" class="section level4">
<h4>Stan code</h4>
<div class="stan">
<pre><code>data {
    int&lt;lower=0&gt; N;
    int&lt;lower=0&gt; n[N];
    int&lt;lower=0&gt; r[N];
    vector[N] x;
}

transformed data {
    vector[N] centered_x;
    real mean_x;
    mean_x &lt;- mean(x);
    centered_x &lt;- x - mean_x;
}

parameters {
    real alpha_star;
    real beta;
}

transformed parameters {
    vector[N] m;
    m &lt;- alpha_star + beta * centered_x;
}

model {
  alpha_star ~ normal(0.0, 1.0E4);  
  beta ~ normal(0.0, 1.0E4);
  r ~ binomial_logit(n, m);
}

generated quantities {
  real alpha; 
  real p[N];
  real llike[N];
  real rhat[N];
  for (i in 1:N)  {
    p[i] &lt;- inv_logit(m[i]);
    llike[i]  &lt;- r[i]*log(p[i]) + (n[i]-r[i])*log(1-p[i]);  
    rhat[i] &lt;- p[i]*n[i];  // fitted values
  }
  alpha &lt;- alpha_star - beta*mean_x;              
} </code></pre>
</div>
</div>
</div>
</div>
<div id="stan-models" class="section level2">
<h2>Stan models</h2>
<p>The following few code examples show how Stan code can be translated in equivalent greta models.</p>
<hr>
<div id="lightspeed" class="section level3">
<h3>Lightspeed</h3>
<p><em>Lightspeed</em> estimates a linear normal model without predictors. The data are 66 measurements from Simon Newcomb and represent the time required for light to travel roughly 7500 meters.</p>
<p>See also the <a href="https://github.com/stan-dev/example-models/wiki/ARM-Models-Sorted-by-Type#no-predictors">Stan examples</a> for details.</p>
<div id="data-2" class="section level4">
<h4>data</h4>
<pre class="text"><code>y &lt;- c(28, 26, 33, 24, 34, -44, 27, 16, 40, -2, 29, 22, 24, 21, 25, 
       30, 23, 29, 31, 19, 24, 20, 36, 32, 36, 28, 25, 21, 28, 29, 
       37, 25, 28, 26, 30, 32, 36, 26, 30, 22, 36, 23, 27, 27, 28, 
       27, 31, 27, 26, 33, 26, 32, 32, 24, 39, 28, 24, 25, 32, 25, 
       29, 27, 28, 29, 16, 23)
n &lt;- length(y)</code></pre>
</div>
<div id="greta-code-2" class="section level4">
<h4>greta code</h4>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1"></a>beta  &lt;-<span class="st"> </span><span class="kw">variable</span>()</span>
<span id="cb32-2"><a href="#cb32-2"></a>sigma &lt;-<span class="st"> </span><span class="kw">variable</span>(<span class="dt">lower =</span> <span class="dv">0</span>)</span>
<span id="cb32-3"><a href="#cb32-3"></a></span>
<span id="cb32-4"><a href="#cb32-4"></a><span class="kw">distribution</span>(y) &lt;-<span class="st"> </span><span class="kw">normal</span>(beta, sigma)</span></code></pre></div>
</div>
<div id="stan-code-2" class="section level4">
<h4>Stan code</h4>
<div class="stan">
<pre><code>data {
  int&lt;lower=0&gt; N; 
  vector[N] y;
}
parameters {
  vector[1] beta;
  real&lt;lower=0&gt; sigma;
} 
model {
  y ~ normal(beta[1],sigma);
}</code></pre>
</div>
<hr>
</div>
</div>
<div id="eight-schools" class="section level3">
<h3>Eight schools</h3>
<p><em>Eight schools</em> estimates the effect of coaching programs in eight schools. The data are 8 measurements of coaching effects along with their standard errors.</p>
<p>See also the <a href="https://github.com/stan-dev/example-models/wiki/ARM-Models-Sorted-by-Type#varying-intercept">Stan example</a> for details.</p>
<div id="data-3" class="section level4">
<h4>data</h4>
<pre class="text"><code>y &lt;- c(28,  8, -3,  7, -1,  1, 18, 12)
sigma_y &lt;- c(15, 10, 16, 11,  9, 11, 10, 18)
N  &lt;- length(y)</code></pre>
</div>
<div id="greta-code-3" class="section level4">
<h4>greta code</h4>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1"></a>sigma_eta &lt;-<span class="st"> </span><span class="kw">inverse_gamma</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb35-2"><a href="#cb35-2"></a>eta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, sigma_eta, <span class="dt">dim=</span>N)</span>
<span id="cb35-3"><a href="#cb35-3"></a></span>
<span id="cb35-4"><a href="#cb35-4"></a>mu_theta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>)</span>
<span id="cb35-5"><a href="#cb35-5"></a>xi &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>)</span>
<span id="cb35-6"><a href="#cb35-6"></a>theta &lt;-<span class="st"> </span>mu_theta <span class="op">+</span><span class="st"> </span>xi <span class="op">*</span><span class="st"> </span>eta</span>
<span id="cb35-7"><a href="#cb35-7"></a></span>
<span id="cb35-8"><a href="#cb35-8"></a><span class="kw">distribution</span>(y) &lt;-<span class="st"> </span><span class="kw">normal</span>(theta, sigma_y)</span></code></pre></div>
</div>
<div id="stan-code-3" class="section level4">
<h4>Stan code</h4>
<div class="stan">
<pre><code>data {
  int&lt;lower=0&gt; N;
  vector[N] y;
  vector[N] sigma_y;
} 
parameters {
  vector[N] eta;
  real mu_theta;
  real&lt;lower=0,upper=100&gt; sigma_eta;
  real xi;
} 
transformed parameters {
  real&lt;lower=0&gt; sigma_theta;
  vector[N] theta;

  theta = mu_theta + xi * eta;
  sigma_theta = fabs(xi) / sigma_eta;
}
model {
  mu_theta ~ normal(0, 100);
  sigma_eta ~ inv_gamma(1, 1); //prior distribution can be changed to uniform

  eta ~ normal(0, sigma_eta);
  xi ~ normal(0, 5);
  y ~ normal(theta,sigma_y);
}</code></pre>
</div>
</div>
</div>
</div>
<div id="ecological-models" class="section level2">
<h2>Ecological models</h2>
<p>Here we provide some examples of common ecological models. We begin with a basic logistic regression often used in species distribution modelling to estimate species probability of presence. We then provide increasingly complex species distribution models, beginning with modelling observation error directly, and moving on to models for multiple species: independently but concurrently modelled species, partially pooled coefficients, repeated measures, and sub-models.</p>
<hr>
<div id="logistic-regression" class="section level3">
<h3>Logistic regression</h3>
<p>A simple logistic regression being to estimate the probability of species presence along a number of environmental gradients.</p>
<div id="data-4" class="section level4">
<h4>data</h4>
<pre class="text"><code># make fake data
n_env &lt;- 3
n_sites &lt;- 20

# n_sites x n_env matrix of environmental variables
env &lt;- matrix(rnorm(n_sites * n_env), nrow = n_sites) 
# n_sites observations of species presence or absence
occupancy &lt;- rbinom(n_sites, 1, 0.5) </code></pre>
</div>
<div id="greta-code-4" class="section level4">
<h4>greta code</h4>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1"></a>alpha &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb38-2"><a href="#cb38-2"></a>beta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_env)</span>
<span id="cb38-3"><a href="#cb38-3"></a></span>
<span id="cb38-4"><a href="#cb38-4"></a><span class="co"># logit-linear model</span></span>
<span id="cb38-5"><a href="#cb38-5"></a>linear_predictor &lt;-<span class="st"> </span>alpha <span class="op">+</span><span class="st"> </span>env <span class="op">%*%</span><span class="st"> </span>beta</span>
<span id="cb38-6"><a href="#cb38-6"></a>p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(linear_predictor)</span>
<span id="cb38-7"><a href="#cb38-7"></a></span>
<span id="cb38-8"><a href="#cb38-8"></a><span class="co"># distribution (likelihood) over observed values</span></span>
<span id="cb38-9"><a href="#cb38-9"></a><span class="kw">distribution</span>(occupancy) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(p)</span></code></pre></div>
<hr>
</div>
</div>
<div id="poisson-regression" class="section level3">
<h3>Poisson regression</h3>
<p>An example of a simple poisson regression being used to estimate the abundance of a species along a number of environmental gradients.</p>
<div id="data-5" class="section level4">
<h4>data</h4>
<pre class="text"><code># make fake data
n_env &lt;- 3
n_sites &lt;- 20

# n_sites x n_env matrix of environmental variables
env &lt;- matrix(rnorm(n_sites * n_env), nrow = n_sites) 
# n_sites observations of species abundance
occupancy &lt;- rpois(n_sites, 5) </code></pre>
</div>
<div id="greta-code-5" class="section level4">
<h4>greta code</h4>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1"></a>alpha &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb40-2"><a href="#cb40-2"></a>beta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_env)</span>
<span id="cb40-3"><a href="#cb40-3"></a>linear_predictor &lt;-<span class="st"> </span>alpha <span class="op">+</span><span class="st"> </span>env <span class="op">%*%</span><span class="st"> </span>beta</span>
<span id="cb40-4"><a href="#cb40-4"></a>lambda &lt;-<span class="st"> </span><span class="kw">exp</span>(linear_predictor)</span>
<span id="cb40-5"><a href="#cb40-5"></a><span class="kw">distribution</span>(occupancy) &lt;-<span class="st"> </span><span class="kw">poisson</span>(lambda)</span></code></pre></div>
<hr>
</div>
</div>
<div id="logistic-regression-with-error-term" class="section level3">
<h3>Logistic regression with error term</h3>
<p>This is an example of a simple logistic regression with an extra observation-level error term, to model over-dispersion or clustering in occupancy data from multiple visits.</p>
<div id="data-6" class="section level4">
<h4>data</h4>
<pre class="text"><code># make fake data
n_env &lt;- 3
n_sites &lt;- 20
n_obs &lt;- 5

# n_sites x n_env matrix of environmental variables
env &lt;- matrix(rnorm(n_sites * n_env), nrow = n_sites) 
# n_sites observations of species presence or absence over n_obs visits
occupancy &lt;- rbinom(n_sites, n_obs, 0.5)</code></pre>
</div>
<div id="greta-code-6" class="section level4">
<h4>greta code</h4>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1"></a>alpha &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb42-2"><a href="#cb42-2"></a>beta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_env)</span>
<span id="cb42-3"><a href="#cb42-3"></a>error &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_sites)</span>
<span id="cb42-4"><a href="#cb42-4"></a></span>
<span id="cb42-5"><a href="#cb42-5"></a><span class="co"># logit-linear model with extra variation</span></span>
<span id="cb42-6"><a href="#cb42-6"></a>linear_predictor &lt;-<span class="st"> </span>alpha <span class="op">+</span><span class="st"> </span>env <span class="op">%*%</span><span class="st"> </span>beta <span class="op">+</span><span class="st"> </span>error</span>
<span id="cb42-7"><a href="#cb42-7"></a>p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(linear_predictor)</span>
<span id="cb42-8"><a href="#cb42-8"></a></span>
<span id="cb42-9"><a href="#cb42-9"></a><span class="co"># distribution (likelihood) over observed values</span></span>
<span id="cb42-10"><a href="#cb42-10"></a><span class="kw">distribution</span>(occupancy) &lt;-<span class="st"> </span><span class="kw">binomial</span>(n_obs, p)</span></code></pre></div>
<hr>
</div>
</div>
<div id="multiple-species-modelling-independently-and-concurrently" class="section level3">
<h3>Multiple species modelling independently and concurrently</h3>
<p>An example of a logistic regression being used to estimate the probability of multiple species’ presences along a number of environmental gradients. Although modelled concurrently, the random variables for each species are independent. We first simulate some data to model followed by the <code>greta</code> code.</p>
<p>Where a single observation per species and location would have a bernoulli error distribution, multiple observations for each species and location have a binomial distribution.</p>
<p>When modelling multiple species (or other grouping factor), we need an extra step in constructing the linear predictor. In order to add multiple <code>greta</code> arrays together <em>for each species</em> we can use the <code>sweep()</code> function.</p>
<div id="data-7" class="section level4">
<h4>data</h4>
<pre class="text"><code># make fake data
n_species &lt;- 5
n_env &lt;- 3
n_sites &lt;- 20

env &lt;- matrix(rnorm(n_sites * n_env), nrow = n_sites)
occupancy &lt;- matrix(rbinom(n_species * n_sites, 1, 0.5), nrow = n_sites)</code></pre>
</div>
<div id="greta-code-7" class="section level4">
<h4>greta code</h4>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1"></a>alpha &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_species)</span>
<span id="cb44-2"><a href="#cb44-2"></a>beta &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> <span class="kw">c</span>(n_env, n_species))</span>
<span id="cb44-3"><a href="#cb44-3"></a></span>
<span id="cb44-4"><a href="#cb44-4"></a>env_effect &lt;-<span class="st"> </span>env <span class="op">%*%</span><span class="st"> </span>beta</span>
<span id="cb44-5"><a href="#cb44-5"></a></span>
<span id="cb44-6"><a href="#cb44-6"></a><span class="co"># add intercepts for all species</span></span>
<span id="cb44-7"><a href="#cb44-7"></a>linear_predictor &lt;-<span class="st"> </span><span class="kw">sweep</span>(env_effect, <span class="dv">2</span>, alpha, <span class="dt">FUN =</span> <span class="st">&#39;+&#39;</span>)</span>
<span id="cb44-8"><a href="#cb44-8"></a></span>
<span id="cb44-9"><a href="#cb44-9"></a><span class="co"># ilogit of linear predictor</span></span>
<span id="cb44-10"><a href="#cb44-10"></a>p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(linear_predictor)</span>
<span id="cb44-11"><a href="#cb44-11"></a></span>
<span id="cb44-12"><a href="#cb44-12"></a><span class="co"># a single observation means our data are bernoulli distributed</span></span>
<span id="cb44-13"><a href="#cb44-13"></a><span class="kw">distribution</span>(occupancy) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(p)</span></code></pre></div>
<hr>
</div>
</div>
<div id="multiple-species-with-partial-pooling-of-regression-coefficients" class="section level3">
<h3>Multiple species with partial pooling of regression coefficients</h3>
<p>An example of a logistic regression being used to estimate the probability of multiple species’ presences along a number of environmental gradients. Instead of assuming independence of species regression coefficients, we assume they are drawn from a shared distribution. We partially pool species responses. This gives us not ony the regression coefficients for each species but also a global average coefficient and a measure of variation between species responses to environmental gradients.</p>
<div id="data-8" class="section level4">
<h4>data</h4>
<pre class="text"><code># make fake data
n_species &lt;- 5
n_env &lt;- 1
n_sites &lt;- 50

env &lt;- matrix(rnorm(n_sites * n_env), nrow = n_sites)
occupancy &lt;- matrix(rbinom(n_sites * n_species, 1, 0.5), nrow = n_sites)</code></pre>
</div>
<div id="greta-code-8" class="section level4">
<h4>greta code</h4>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1"></a>global_alpha &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> <span class="dv">1</span>)</span>
<span id="cb46-2"><a href="#cb46-2"></a>global_alpha_sd &lt;-<span class="st"> </span><span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> <span class="dv">1</span>) </span>
<span id="cb46-3"><a href="#cb46-3"></a>alpha &lt;-<span class="st"> </span><span class="kw">normal</span>(global_alpha, global_alpha_sd, <span class="dt">dim =</span> n_species)</span>
<span id="cb46-4"><a href="#cb46-4"></a></span>
<span id="cb46-5"><a href="#cb46-5"></a>global_betas &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_env)</span>
<span id="cb46-6"><a href="#cb46-6"></a>global_betas_sd &lt;-<span class="st"> </span><span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> n_env)</span>
<span id="cb46-7"><a href="#cb46-7"></a>beta &lt;-<span class="st"> </span><span class="kw">normal</span>(global_betas, global_betas_sd, <span class="dt">dim =</span> <span class="kw">c</span>(n_env, n_species))</span>
<span id="cb46-8"><a href="#cb46-8"></a></span>
<span id="cb46-9"><a href="#cb46-9"></a>env_effect &lt;-<span class="st"> </span>env <span class="op">%*%</span><span class="st"> </span>beta</span>
<span id="cb46-10"><a href="#cb46-10"></a></span>
<span id="cb46-11"><a href="#cb46-11"></a><span class="co"># add intercepts for all species</span></span>
<span id="cb46-12"><a href="#cb46-12"></a>linear_predictor &lt;-<span class="st"> </span><span class="kw">sweep</span>(env_effect, <span class="dv">2</span>, alpha, <span class="dt">FUN =</span> <span class="st">&#39;+&#39;</span>)</span>
<span id="cb46-13"><a href="#cb46-13"></a></span>
<span id="cb46-14"><a href="#cb46-14"></a><span class="co"># ilogit of linear predictor</span></span>
<span id="cb46-15"><a href="#cb46-15"></a>p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(linear_predictor)</span>
<span id="cb46-16"><a href="#cb46-16"></a></span>
<span id="cb46-17"><a href="#cb46-17"></a><span class="kw">distribution</span>(occupancy) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(p)</span></code></pre></div>
<hr>
</div>
</div>
<div id="multiple-species-with-sub-model-for-regression-coefficients" class="section level3">
<h3>Multiple species with sub-model for regression coefficients</h3>
<p>An example of a logistic regression being used to estimate the probability of multiple species’ presences along a number of environmental gradients. Instead of assuming independence of species regression coefficients, or partial pooling in shared distributions, we use a sub-model to estimate species regression coefficients. In this case, we’re using species traits to estimate their response to different environmental gradients.</p>
<p>Because we’re building a sub-model, it’s more efficient to simply add a column of ones to dataframes for the base model and sub-model. This is simply to prevent our code from becoming too cumbersome. If we didn’t want to use our sub-model to estimate the intercept, we would not need to include the column of ones in the environmental dataframe.</p>
<div id="data-9" class="section level4">
<h4>data</h4>
<pre class="text"><code># make fake data
n_species &lt;- 3
n_env &lt;- 1
n_sites &lt;- 5
n_traits &lt;- 1

# n_sites x n_env matrix of environmental variables
env &lt;- matrix(rnorm(n_sites * n_env), nrow = n_sites)
# n_species * n_traits matix of trait variables
traits &lt;- matrix(rnorm(n_species * n_traits), nrow = n_species)
# n_sites * n_species matrix of observed occupancy
occupancy &lt;- matrix(rbinom(n_sites * n_species, 1, 0.5), nrow = n_sites)</code></pre>
</div>
<div id="greta-code-9" class="section level4">
<h4>greta code</h4>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1"></a><span class="co"># include a column of 1&#39;s for intercept estimation in the sub-model (traits) and base model</span></span>
<span id="cb48-2"><a href="#cb48-2"></a>traits &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">rep</span>(<span class="dv">1</span>, n_species), traits)</span>
<span id="cb48-3"><a href="#cb48-3"></a>env &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">rep</span>(<span class="dv">1</span>, n_sites), env)</span>
<span id="cb48-4"><a href="#cb48-4"></a></span>
<span id="cb48-5"><a href="#cb48-5"></a><span class="co"># redefine n_env and n_traits after adding columns for intercepts</span></span>
<span id="cb48-6"><a href="#cb48-6"></a>n_env &lt;-<span class="st"> </span><span class="kw">ncol</span>(env)</span>
<span id="cb48-7"><a href="#cb48-7"></a>n_traits &lt;-<span class="st"> </span><span class="kw">ncol</span>(traits)</span>
<span id="cb48-8"><a href="#cb48-8"></a></span>
<span id="cb48-9"><a href="#cb48-9"></a><span class="co"># sub-model parameters have normal prior distributions</span></span>
<span id="cb48-10"><a href="#cb48-10"></a>g &lt;-<span class="st"> </span><span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">dim =</span> <span class="kw">c</span>(n_env, n_traits))</span>
<span id="cb48-11"><a href="#cb48-11"></a><span class="co"># parameters of the base model are a function of the parameters of the sub-model</span></span>
<span id="cb48-12"><a href="#cb48-12"></a>beta &lt;-<span class="st">  </span>g <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(traits) </span>
<span id="cb48-13"><a href="#cb48-13"></a></span>
<span id="cb48-14"><a href="#cb48-14"></a><span class="co"># use the coefficients to get the model linear predictor</span></span>
<span id="cb48-15"><a href="#cb48-15"></a>linear_predictor &lt;-<span class="st"> </span>env <span class="op">%*%</span><span class="st"> </span>beta </span>
<span id="cb48-16"><a href="#cb48-16"></a></span>
<span id="cb48-17"><a href="#cb48-17"></a><span class="co"># use the logit link to get probabilities of occupancy</span></span>
<span id="cb48-18"><a href="#cb48-18"></a>p &lt;-<span class="st"> </span><span class="kw">ilogit</span>(linear_predictor)</span>
<span id="cb48-19"><a href="#cb48-19"></a></span>
<span id="cb48-20"><a href="#cb48-20"></a><span class="co"># data are bernoulli distributed</span></span>
<span id="cb48-21"><a href="#cb48-21"></a><span class="kw">distribution</span>(occupancy) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(p)</span></code></pre></div>
<hr>
</div>
</div>
<div id="cormack-jolly-seber-model" class="section level3">
<h3>Cormack-Jolly-Seber model</h3>
<p><em>Cormack-Jolly-Seber</em> (CJS) models estimate probabilities of survival and recapture from mark-recapture data. These models assume that we can only ever see individuals that have been initially marked and released or recaptured following release (i.e. individuals do not exist until first observed). The two key parameters are survival, <span class="math inline">\(\phi\)</span>, and probability of recapture, <span class="math inline">\(p\)</span>. There is an additional derived parameter, <span class="math inline">\(\chi\)</span>, which is the probability that an individual is not recaptured following its final capture. <span class="math inline">\(\chi\)</span> marginalises over multiple scenarios in which the individual is not observed either because it has died or because it is alive but not detected.</p>
<p>The <a href="http://www.phidot.org/software/mark/docs/book/">introductory book</a> to the program MARK has a lot of information on mark-recapture models, including CJS models (starting in Ch. 1) and the broader class of Jolly-Seber models (Ch. 12). There is also a section on mark-recapture models in the <a href="http://mc-stan.org/users/documentation/">Stan language manual</a>, which goes through the derivation of the parameter <span class="math inline">\(\chi\)</span>.</p>
<div id="data-10" class="section level4">
<h4>data</h4>
<div class="data">
<pre class="text"><code>n_obs &lt;- 100
n_time &lt;- 20
y &lt;- matrix(sample(c(0, 1), size = (n_obs * n_time), replace = TRUE),
            ncol = n_time)</code></pre>
</div>
</div>
<div id="greta-code-10" class="section level4">
<h4>greta code</h4>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1"></a><span class="co"># data summaries</span></span>
<span id="cb50-2"><a href="#cb50-2"></a>first_obs &lt;-<span class="st"> </span><span class="kw">apply</span>(y, <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="kw">min</span>(<span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)))</span>
<span id="cb50-3"><a href="#cb50-3"></a>final_obs &lt;-<span class="st"> </span><span class="kw">apply</span>(y, <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="kw">max</span>(<span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)))</span>
<span id="cb50-4"><a href="#cb50-4"></a>obs_id &lt;-<span class="st"> </span><span class="kw">apply</span>(y, <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="kw">seq</span>(<span class="kw">min</span>(<span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)), <span class="kw">max</span>(<span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)), <span class="dt">by =</span> <span class="dv">1</span>)[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb50-5"><a href="#cb50-5"></a>obs_id &lt;-<span class="st"> </span><span class="kw">unlist</span>(obs_id)</span>
<span id="cb50-6"><a href="#cb50-6"></a>capture_vec &lt;-<span class="st"> </span><span class="kw">apply</span>(y, <span class="dv">1</span>, <span class="cf">function</span>(x) x[<span class="kw">min</span>(<span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>))<span class="op">:</span><span class="kw">max</span>(<span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>))][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb50-7"><a href="#cb50-7"></a>capture_vec &lt;-<span class="st"> </span><span class="kw">unlist</span>(capture_vec)</span>
<span id="cb50-8"><a href="#cb50-8"></a></span>
<span id="cb50-9"><a href="#cb50-9"></a><span class="co"># priors</span></span>
<span id="cb50-10"><a href="#cb50-10"></a>phi &lt;-<span class="st"> </span><span class="kw">beta</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dt">dim =</span> n_time)</span>
<span id="cb50-11"><a href="#cb50-11"></a>p &lt;-<span class="st"> </span><span class="kw">beta</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dt">dim =</span> n_time)</span>
<span id="cb50-12"><a href="#cb50-12"></a></span>
<span id="cb50-13"><a href="#cb50-13"></a><span class="co"># derived parameter</span></span>
<span id="cb50-14"><a href="#cb50-14"></a>chi &lt;-<span class="st"> </span><span class="kw">ones</span>(n_time)</span>
<span id="cb50-15"><a href="#cb50-15"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_len</span>(n_time <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) {</span>
<span id="cb50-16"><a href="#cb50-16"></a>  tn &lt;-<span class="st"> </span>n_time <span class="op">-</span><span class="st"> </span>i</span>
<span id="cb50-17"><a href="#cb50-17"></a>  chi[tn] &lt;-<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>phi[tn]) <span class="op">+</span><span class="st"> </span>phi[tn] <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p[tn <span class="op">+</span><span class="st"> </span><span class="dv">1</span>]) <span class="op">*</span><span class="st"> </span>chi[tn <span class="op">+</span><span class="st"> </span><span class="dv">1</span>]</span>
<span id="cb50-18"><a href="#cb50-18"></a>}</span>
<span id="cb50-19"><a href="#cb50-19"></a></span>
<span id="cb50-20"><a href="#cb50-20"></a><span class="co"># dummy variables</span></span>
<span id="cb50-21"><a href="#cb50-21"></a>alive_data &lt;-<span class="st"> </span><span class="kw">ones</span>(<span class="kw">length</span>(obs_id))            <span class="co"># definitely alive</span></span>
<span id="cb50-22"><a href="#cb50-22"></a>not_seen_last &lt;-<span class="st"> </span>final_obs <span class="op">!=</span><span class="st"> </span><span class="dv">20</span>              <span class="co"># ignore observations in last timestep</span></span>
<span id="cb50-23"><a href="#cb50-23"></a>final_observation &lt;-<span class="st"> </span><span class="kw">ones</span>(<span class="kw">sum</span>(not_seen_last)) <span class="co"># final observation</span></span>
<span id="cb50-24"><a href="#cb50-24"></a></span>
<span id="cb50-25"><a href="#cb50-25"></a><span class="co"># set likelihoods</span></span>
<span id="cb50-26"><a href="#cb50-26"></a><span class="kw">distribution</span>(alive_data) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(phi[obs_id <span class="op">-</span><span class="st"> </span><span class="dv">1</span>])</span>
<span id="cb50-27"><a href="#cb50-27"></a><span class="kw">distribution</span>(capture_vec) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(p[obs_id])</span>
<span id="cb50-28"><a href="#cb50-28"></a><span class="kw">distribution</span>(final_observation) &lt;-<span class="st"> </span><span class="kw">bernoulli</span>(chi[final_obs[not_seen_last]])</span></code></pre></div>
</div>
<div id="bugsjags-code-2" class="section level4">
<h4>BUGS/JAGS code</h4>
<div class="bugs">
<pre><code>model {
  # priors
  for (t in 1:(n_time - 1)) {
    phi[t] ~ dunif(0, 1)
    p[t] ~ dunif(0, 1)
  }
  # likelihood
  for (i in 1:n_obs) {
    z[i, first_obs[i]] &lt;- 1   # state at first capture must be 1!
    for (t in (first_obs[i] + 1):n_time) {
      mu1[i, t] &lt;- phi[t - 1] * z[i, t - 1] 
      z[i, t] ~ dbern(mu1[i, t])   # true state
      mu2[i, t] &lt;- p[t - 1] * z[i, t]
      y[i, t] ~ dbern(mu2[i, t])      # observed state
    }
  }
}</code></pre>
</div>
</div>
<div id="stan-code-4" class="section level4">
<h4>Stan code</h4>
<div class="stan">
<pre><code>/**
 * Cormack-Jolly-Seber Model
 * 
 * following section 1.2.1 of:
 * http://www.maths.otago.ac.nz/home/resources/theses/PhD_Matthew_Schofield.pdf
 *
 */
data {
  int&lt;lower=2&gt; K;                      // capture events
  int&lt;lower=0&gt; I;                      // number of individuals
  int&lt;lower=0,upper=1&gt; X[I,K];         // X[i,k]: individual i captured at k
}
transformed data {
  int&lt;lower=0,upper=K+1&gt; first[I];     // first[i]: ind i first capture
  int&lt;lower=0,upper=K+1&gt; last[I];      // last[i]:  ind i last capture
  int&lt;lower=0,upper=I&gt; n_captured[K];  // n_capt[k]: num aptured at k

  first &lt;- rep_array(K+1,I);
  last &lt;- rep_array(0,I);
  for (i in 1:I) {
    for (k in 1:K) {
      if (X[i,k] == 1) {
        if (k &lt; first[i]) 
          first[i] &lt;- k;
        if (k &gt; last[i]) 
          last[i] &lt;- k;
      }
    }
  }

  n_captured &lt;- rep_array(0,K);
  for (i in 1:I)
    for (k in 1:K)
      n_captured[k] &lt;- n_captured[k] + X[i,k];
}
parameters {
  vector&lt;lower=0,upper=1&gt;[K-1] phi;  // phi[k]: Pr[alive at k + 1 | alive at k]
  vector&lt;lower=0,upper=1&gt;[K] p;      // p[k]: Pr[capture at k]

  // note:  p[1] not used in model and hence not identified
}
transformed parameters {
  vector&lt;lower=0,upper=1&gt;[K] chi;   // chi[k]: Pr[no capture &gt;  k | alive at k]
  {
    int k;
    chi[K] &lt;- 1.0;              
    k &lt;- K - 1;
    while (k &gt; 0) {
      chi[k] &lt;- (1 - phi[k]) + phi[k] * (1 - p[k+1]) * chi[k+1]; 
      k &lt;- k - 1;
    }
  }
}
model {
  for (i in 1:I) {
    if (last[i] &gt; 0) {
      for (k in (first[i]+1):last[i]) {
        increment_log_prob(log(phi[k-1]));     // i survived from k-1 to k
        if (X[i,k] == 1)
          increment_log_prob(log(p[k]));       // i captured at k
        else
          increment_log_prob(log1m(p[k]));     // i not captured at k
      }
      increment_log_prob(log(chi[last[i]]));   // i not seen after last[i]
    }
  }
}
generated quantities {
  // phi[K-1] and p(K) not identified, but product is
  real beta;
  vector&lt;lower=0&gt;[K] pop_hat;  // population

  beta &lt;- phi[K-1] * p[K];

  for (k in 1:K)
    pop_hat[k] &lt;- n_captured[k] / p[k];  
}</code></pre>
</div>
<hr>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
